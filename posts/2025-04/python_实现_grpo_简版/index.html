<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Python 实现 GRPO 简版 - 文字轨迹</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://ixxmu.github.io/posts/2025-04/python_%E5%AE%9E%E7%8E%B0_grpo_%E7%AE%80%E7%89%88/"><meta property="og:site_name" content="文字轨迹"><meta property="og:title" content="Python 实现 GRPO 简版"><meta property="og:description" content="Python 实现 GRPO 简版 by 数据STUDIO 今天我们将深入探讨GRPO的实现。先简要介绍这一概念，讨论方法，然后开始具体实现。"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-04-18T02:34:42+00:00"><meta property="article:modified_time" content="2025-04-18T02:34:42+00:00"><meta property="article:tag" content="Fetched"><meta property="article:tag" content="数据STUDIO"><meta itemprop=name content="Python 实现 GRPO 简版"><meta itemprop=description content="Python 实现 GRPO 简版 by 数据STUDIO 今天我们将深入探讨GRPO的实现。先简要介绍这一概念，讨论方法，然后开始具体实现。"><meta itemprop=datePublished content="2025-04-18T02:34:42+00:00"><meta itemprop=dateModified content="2025-04-18T02:34:42+00:00"><meta itemprop=wordCount content="614"><meta itemprop=keywords content="Fetched,数据STUDIO"><meta name=twitter:card content="summary"><meta name=twitter:title content="Python 实现 GRPO 简版"><meta name=twitter:description content="Python 实现 GRPO 简版 by 数据STUDIO 今天我们将深入探讨GRPO的实现。先简要介绍这一概念，讨论方法，然后开始具体实现。"><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../css/style.css><link rel=stylesheet href=../../../css/custom.css><link rel="shortcut icon" href=../../../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../ title=文字轨迹 rel=home><div class="logo__item logo__text"><div class=logo__title>文字轨迹</div><div class=logo__tagline>故事流淌过的地方</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../posts/><span class=menu__text>文章</span></a></li><li class=menu__item><a class=menu__link href=../../../tags/><span class=menu__text>标签</span></a></li><li class=menu__item><a class=menu__link href=../../../about/><span class=menu__text>关于</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><meta name=referrer content="never"><h1 class=post__title>Python 实现 GRPO 简版</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2025-04-18T02:34:42Z>2025-04-18</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../categories/duty/ rel=category>Duty</a></span></div><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 16 16"><path d="M8 1c2 0 3.5 2 3.5 4.5S10 9 10 9c3 1 4 2 4 6H2c0-4 1-5 4-6 0 0-1.5-1-1.5-3.5S6 1 8 1"/></svg><span class=meta__text>Bloger</span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#python-实现-grpo-简版-by-数据studio>Python 实现 GRPO 简版 by 数据STUDIO</a></li></ul></nav></div></div><div class="content post__content clearfix"><h2 id=python-实现-grpo-简版-by-数据studio>Python 实现 GRPO 简版 by 数据STUDIO</h2><div><p data-mpa-powered-by=yiban.io><span leaf><img data-ratio=0.1782178217821782 data-type=gif data-w=606 data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibSBAB7MzqzBARx8T3TBZruGNeET47qhWwjg4BqHeZ1x5mGWvyVXy4pJclLnUblwlbcScjxFGNP5A/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibSBAB7MzqzBARx8T3TBZruGNeET47qhWwjg4BqHeZ1x5mGWvyVXy4pJclLnUblwlbcScjxFGNP5A/640?wx_fmt=gif"></span><span leaf><br></span></p><section data-tool=mdnice编辑器 data-website=https://www.mdnice.com><section nodeleaf><img data-ratio=0.15255813953488373 data-type=gif data-w=1075 data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibWWVA1RARlHw5jnibnfd6JGic5gARmlWo6uUAWD1ibWdqOWynFaJMcVWXw42637bhaKOybTxQgib4DEQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ibWWVA1RARlHw5jnibnfd6JGic5gARmlWo6uUAWD1ibWdqOWynFaJMcVWXw42637bhaKOybTxQgib4DEQ/640?wx_fmt=gif"></section><p data-tool=mdnice编辑器><span leaf>今天我们将深入探讨GRPO的实现。先简要介绍这一概念，讨论方法，然后开始具体实现。</span></p><p data-tool=mdnice编辑器><span leaf><img data-imgfileid=100106564 data-type=png data-ratio=0.5981481481481481 data-w=1080 data-src="https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7icmiaFXCvSicjxy977LFVaPO6FFDjMrfRP0K4qyQ5rO0uhMqEjE3TwYFbtUnKjeQreiaExmVGUCt7gicA/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/mmbiz_png/gX9JE5tiaI7icmiaFXCvSicjxy977LFVaPO6FFDjMrfRP0K4qyQ5rO0uhMqEjE3TwYFbtUnKjeQreiaExmVGUCt7gicA/640?wx_fmt=png&amp;from=appmsg"></span></p><h2 data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><span></span><span><span leaf>什么是GRPO？</span></span><span></span></h2><p data-tool=mdnice编辑器><span leaf>GRPO是一种训练技术，旨在通过捕捉特定偏好的奖励函数来优化语言模型。与其他强化学习方法（如PPO或RLHF）不同，GRPO不需要复杂的评判模型和大量计算资源，而是直接优化语言模型，并通过在生成的响应组内计算相对优势来实现目标。</span></p><h2 data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><span></span><span><span leaf>GRPO的关键特点</span></span><span></span></h2><h3 data-tool=mdnice编辑器><span></span><span><span leaf>GRPO的独特之处</span></span><span></span></h3><p data-tool=mdnice编辑器><span leaf>GRPO是一种新兴的强化学习技术，相比传统方法具有以下优势：</span></p><ul><li><section><strong><span leaf>直接优化</span></strong><span leaf>：不同于需要独立奖励模型的方法，GRPO直接使用显式奖励函数优化语言模型。</span></section></li><li><section><strong><span leaf>多奖励信号</span></strong><span leaf>：可以定义多个奖励函数，针对生成内容的不同方面（如正确性、格式、风格）。</span></section></li><li><section><strong><span leaf>探索效率</span></strong><span leaf>：GRPO通过在训练过程中为每个提示生成多个补全内容，有效探索输出空间。</span></section></li></ul><h3 data-tool=mdnice编辑器><span></span><span><span leaf>奖励函数</span></span><span></span></h3><p data-tool=mdnice编辑器><span leaf>代码实现了多个协同工作的奖励函数，用于指导模型：</span></p><ul><li><section><strong><span leaf>correctness_reward_func</span></strong><span leaf>：当模型提取的答案与真实答案匹配时，奖励2.0分。这是事实正确性的主要学习信号。</span></section></li><li><section><strong><span leaf>int_reward_func</span></strong><span leaf>：当答案是数字时奖励0.5分，适用于数学问题，引导模型生成数值响应。</span></section></li><li><section><strong><span leaf>soft_format_reward_func和strict_format_reward_func</span></strong><span leaf>：奖励正确的XML格式（0.5分），教导模型使用正确的标签结构响应。</span></section></li><li><section><strong><span leaf>xmlcount_reward_func</span></strong><span leaf>：为每个正确使用的XML标签提供部分奖励（每个标签0.125分），形成平滑的学习梯度。</span></section></li></ul><h3 data-tool=mdnice编辑器><span></span><span><span leaf>实现组件</span></span><span></span></h3><ul><li><section><strong><span leaf>奖励函数</span></strong><span leaf>：根据特定标准评估模型输出：</span></section></li><ul><li><section><span leaf>正确性：检查提取的答案是否与真实答案匹配。</span></section></li><li><section><span leaf>格式遵循：确保响应符合请求的XML格式。</span></section></li><li><section><span leaf>整数检测：奖励数值答案。</span></section></li></ul><li><section><strong><span leaf>数据集准备</span></strong><span leaf>：使用GSM8K（数学应用题）数据集，并进行特定格式化。</span></section></li><li><section><strong><span leaf>训练配置</span></strong><span leaf>：使用LoRA进行参数高效微调。</span></section></li></ul><h3 data-tool=mdnice编辑器><span></span><span><span leaf>训练过程</span></span><span></span></h3><ul><li><section><span leaf>对于数据集中的每个提示，模型生成多个补全内容（由</span><strong><span leaf>num_generations</span></strong><span leaf>设置，代码中为4）。</span></section></li><li><section><span leaf>每个补全内容由所有奖励函数评估。</span></section></li><li><section><span leaf>奖励用于更新模型权重，鼓励模型生成更高奖励的输出。</span></section></li><li><section><span leaf>此过程持续指定的周期数。</span></section></li></ul><h3 data-tool=mdnice编辑器><span></span><span><span leaf>参数高效微调</span></span><span></span></h3><p data-tool=mdnice编辑器><span leaf>我们使用LoRA（低秩适应）高效微调模型。LoRA向注意力层添加小型可训练的“适配器”矩阵，大幅减少训练参数数量（通常>99%）。</span><strong><span leaf>peft_config</span></strong><span leaf>定义了目标层和适配器的秩。</span></p><h3 data-tool=mdnice编辑器><span></span><span><span leaf>实施考虑</span></span><span></span></h3><ul><li><section><span leaf>使用较小的模型（Qwen2.5-1.5B-Instruct）以适应内存限制。</span></section></li><li><section><span leaf>减小批次大小和生成数量以管理内存使用，并使用较小的数据集子集（20个示例）进行快速实验。</span></section></li><li><section><span leaf>测试代码可在训练后立即评估结果。可通过增加</span><strong><span leaf>max_samples</span></strong><span leaf>行更全面的训练，或尝试不同的奖励函数。</span></section></li></ul><h2 data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><span></span><span><span leaf>代码实现</span></span><span></span></h2><h3 data-tool=mdnice编辑器><span></span><span><span leaf>安装所需包</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>pip install -q transformers datasets trl peft accelerate</span><span leaf><br></span><span leaf>import re</span><span leaf><br></span><span leaf>import torch</span><span leaf><br></span><span leaf>import numpy as np</span><span leaf><br></span><span leaf>from datasets import load_dataset, Dataset</span><span leaf><br></span><span leaf>from transformers import AutoTokenizer, AutoModelForCausalLM</span><span leaf><br></span><span leaf>from peft import LoraConfig, get_peft_model</span><span leaf><br></span><span leaf>from trl import GRPOConfig, GRPOTrainer</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>定义系统和响应提示</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>SYSTEM_PROMPT = </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>请按以下格式响应：  </span><span leaf><br></span><span leaf>&lt;reasoning&gt;  </span><span leaf><br></span><span leaf>...  </span><span leaf><br></span><span leaf>&lt;/reasoning&gt;  </span><span leaf><br></span><span leaf>&lt;answer&gt;  </span><span leaf><br></span><span leaf>...  </span><span leaf><br></span><span leaf>&lt;/answer&gt;  </span><span leaf><br></span><span leaf>"</span></span><span><span leaf>""</span></span><span leaf><br></span><span leaf><br></span><span leaf>XML_COT_FORMAT = </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>&lt;reasoning&gt;  </span><span leaf><br></span><span leaf>{reasoning}  </span><span leaf><br></span><span leaf>&lt;/reasoning&gt;  </span><span leaf><br></span><span leaf>&lt;answer&gt;  </span><span leaf><br></span><span leaf>{answer}  </span><span leaf><br></span><span leaf>&lt;/answer&gt;  </span><span leaf><br></span><span leaf>"</span></span><span><span leaf>""</span></span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>提取答案的辅助函数</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>def extract_xml_answer(text: str) -&gt; str:  </span><span leaf><br></span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"从XML格式的响应中提取答案部分。"</span></span><span><span leaf>""</span></span><span leaf><br></span><span leaf>    </span><span><span leaf>if</span></span><span><span leaf>"&lt;answer&gt;"</span></span><span leaf> not </span><span><span leaf>in</span></span><span leaf> text or </span><span><span leaf>"&lt;/answer&gt;"</span></span><span leaf> not </span><span><span leaf>in</span></span><span leaf> text:  </span><span leaf><br></span><span leaf>        </span><span><span leaf>return</span></span><span><span leaf>""</span></span><span leaf><br></span><span leaf>    answer = text.split(</span><span><span leaf>"&lt;/answer&gt;"</span></span><span leaf>)[-1]  </span><span leaf><br></span><span leaf>    answer = answer.split(</span><span><span leaf>"&lt;answer&gt;"</span></span><span leaf>)[0]  </span><span leaf><br></span><span leaf>    </span><span><span leaf>return</span></span><span leaf> answer.strip()  </span><span leaf><br></span><span leaf><br></span><span leaf>def extract_hash_answer(text: str) -&gt; str:  </span><span leaf><br></span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"从GSM8K格式中提取答案（###标记之后）。"</span></span><span><span leaf>""</span></span><span leaf><br></span><span leaf>    </span><span><span leaf>if</span></span><span><span leaf>"####"</span></span><span leaf> not </span><span><span leaf>in</span></span><span leaf> text:  </span><span leaf><br></span><span leaf>        </span><span><span leaf>return</span></span><span><span leaf>""</span></span><span leaf><br></span><span leaf>    </span><span><span leaf>return</span></span><span leaf> text.split(</span><span><span leaf>"###"</span></span><span leaf>)[1].strip().replace(</span><span><span leaf>"."</span></span><span leaf>, </span><span><span leaf>""</span></span><span leaf>).replace(</span><span><span leaf>"$"</span></span><span leaf>, </span><span><span leaf>""</span></span><span leaf>)</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>加载并准备GSM8K数据集</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>def get_gsm8k_questions(split=</span><span><span leaf>"train"</span></span><span leaf>, max_samples=100) -&gt; Dataset:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    加载GSM8K数据集并格式化为GRPO训练所需形式。  </span><span leaf><br></span><span leaf>    参数：  </span><span leaf><br></span><span leaf>        split: 使用的数据集划分（train, test）  </span><span leaf><br></span><span leaf>        max_samples: 使用的最大样本数（用于快速实验）  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    data = load_dataset(</span><span><span leaf>'openai/gsm8k'</span></span><span leaf>, </span><span><span leaf>'main'</span></span><span leaf>)[split]  </span><span leaf>    </span><span><span leaf># 限制数据集大小以加快实验  </span></span><span leaf>    </span><span><span leaf>if</span></span><span leaf> max_samples and max_samples &lt; len(data):  </span><span leaf>        data = data.select(range(max_samples))  </span><span leaf>    </span><span><span leaf># 格式化数据为所需的提示结构  </span></span><span leaf>    data = data.map(lambda x: {  </span><span leaf>        </span><span><span leaf>'prompt'</span></span><span leaf>: [  </span><span leaf>            {</span><span><span leaf>'role'</span></span><span leaf>: </span><span><span leaf>'system'</span></span><span leaf>, </span><span><span leaf>'content'</span></span><span leaf>: SYSTEM_PROMPT},  </span><span leaf>            {</span><span><span leaf>'role'</span></span><span leaf>: </span><span><span leaf>'user'</span></span><span leaf>, </span><span><span leaf>'content'</span></span><span leaf>: x[</span><span><span leaf>'question'</span></span><span leaf>]}  </span><span leaf>        ],  </span><span leaf>        </span><span><span leaf>'answer'</span></span><span leaf>: extract_hash_answer(x[</span><span><span leaf>'answer'</span></span><span leaf>])  </span><span leaf>    })  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> data</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>奖励函数</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>def correctness_reward_func(prompts, completions, answer, **kwargs):  </span><span leaf><br></span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    检查提取的答案是否与真实答案匹配的奖励函数。  </span><span leaf><br></span><span leaf>    正确答案返回2.0，否则返回0.0。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    responses = [completion[0][</span><span><span leaf>'content'</span></span><span leaf>] </span><span><span leaf>for</span></span><span leaf> completion </span><span><span leaf>in</span></span><span leaf> completions]  </span><span leaf>    q = prompts[0][-1][</span><span><span leaf>'content'</span></span><span leaf>]  </span><span leaf>    extracted_responses = [extract_xml_answer(r) </span><span><span leaf>for</span></span><span leaf> r </span><span><span leaf>in</span></span><span leaf> responses]  </span><span leaf>    </span><span><span leaf># 打印调试信息  </span></span><span leaf>    </span><span><span leaf>if</span></span><span leaf> kwargs.get(</span><span><span leaf>'debug'</span></span><span leaf>, False) and len(responses) &gt; 0:  </span><span leaf>        </span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>'-'</span></span><span leaf>*20)  </span><span leaf>        </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"问题：\n{q}"</span></span><span leaf>)  </span><span leaf>        </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"\n真实答案：\n{answer[0]}"</span></span><span leaf>)  </span><span leaf>        </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"\n模型响应：\n{responses[0]}"</span></span><span leaf>)  </span><span leaf>        </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"\n提取的答案：\n{extracted_responses[0]}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> [2.0 </span><span><span leaf>if</span></span><span leaf> r == a </span><span><span leaf>else</span></span><span leaf> 0.0 </span><span><span leaf>for</span></span><span leaf> r, a </span><span><span leaf>in</span></span><span leaf> zip(extracted_responses, answer)]  </span><span leaf>def int_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf>float</span></span><span leaf>]:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    检查提取的答案是否为数字的奖励函数。  </span><span leaf><br></span><span leaf>    整数答案返回0.5，否则返回0.0。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    responses = [completion[0][</span><span><span leaf>'content'</span></span><span leaf>] </span><span><span leaf>for</span></span><span leaf> completion </span><span><span leaf>in</span></span><span leaf> completions]  </span><span leaf>    extracted_responses = [extract_xml_answer(r) </span><span><span leaf>for</span></span><span leaf> r </span><span><span leaf>in</span></span><span leaf> responses]  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> [0.5 </span><span><span leaf>if</span></span><span leaf> r.isdigit() </span><span><span leaf>else</span></span><span leaf> 0.0 </span><span><span leaf>for</span></span><span leaf> r </span><span><span leaf>in</span></span><span leaf> extracted_responses]  </span><span leaf>def strict_format_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf>float</span></span><span leaf>]:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    检查补全内容是否完全符合格式的奖励函数。  </span><span leaf><br></span><span leaf>    匹配格式返回0.5，否则返回0.0。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    pattern = r</span><span><span leaf>"^\n&lt;reasoning&gt;.*?&lt;/reasoning&gt;\n\n&lt;answer&gt;.*?&lt;/answer&gt;\n$"</span></span><span leaf>    responses = [completion[0][</span><span><span leaf>'content'</span></span><span leaf>] </span><span><span leaf>for</span></span><span leaf> completion </span><span><span leaf>in</span></span><span leaf> completions]  </span><span leaf>    matches = [bool(re.search(pattern, r, flags=re.DOTALL)) </span><span><span leaf>for</span></span><span leaf> r </span><span><span leaf>in</span></span><span leaf> responses]  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> [0.5 </span><span><span leaf>if</span></span><span leaf> match </span><span><span leaf>else</span></span><span leaf> 0.0 </span><span><span leaf>for</span></span><span leaf> match </span><span><span leaf>in</span></span><span leaf> matches]  </span><span leaf>def soft_format_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf>float</span></span><span leaf>]:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    宽松的格式检查奖励函数。  </span><span leaf><br></span><span leaf>    匹配格式返回0.5，否则返回0.0。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    pattern = r</span><span><span leaf>"&lt;reasoning&gt;.*?&lt;/reasoning&gt;.*?&lt;answer&gt;.*?&lt;/answer&gt;"</span></span><span leaf>    responses = [completion[0][</span><span><span leaf>'content'</span></span><span leaf>] </span><span><span leaf>for</span></span><span leaf> completion </span><span><span leaf>in</span></span><span leaf> completions]  </span><span leaf>    matches = [bool(re.search(pattern, r, flags=re.DOTALL)) </span><span><span leaf>for</span></span><span leaf> r </span><span><span leaf>in</span></span><span leaf> responses]  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> [0.5 </span><span><span leaf>if</span></span><span leaf> match </span><span><span leaf>else</span></span><span leaf> 0.0 </span><span><span leaf>for</span></span><span leaf> match </span><span><span leaf>in</span></span><span leaf> matches]  </span><span leaf>def count_xml(text) -&gt; </span><span><span leaf>float</span></span><span leaf>:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    统计XML标签并为每个正确放置的标签提供部分奖励。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    count = 0.0  </span><span leaf>    </span><span><span leaf>if</span></span><span leaf> text.count(</span><span><span leaf>"&lt;reasoning&gt;"</span></span><span leaf>) == 1:  </span><span leaf>        count += 0.125  </span><span leaf>    </span><span><span leaf>if</span></span><span leaf> text.count(</span><span><span leaf>"&lt;/reasoning&gt;"</span></span><span leaf>) == 1:  </span><span leaf>        count += 0.125  </span><span leaf>    </span><span><span leaf>if</span></span><span leaf> text.count(</span><span><span leaf>"&lt;answer&gt;"</span></span><span leaf>) == 1:  </span><span leaf>        count += 0.125  </span><span leaf>    </span><span><span leaf>if</span></span><span leaf> text.count(</span><span><span leaf>"&lt;/answer&gt;"</span></span><span leaf>) == 1:  </span><span leaf>        count += 0.125  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> count  </span><span leaf>def xmlcount_reward_func(completions, **kwargs) -&gt; list[</span><span><span leaf>float</span></span><span leaf>]:  </span><span leaf>    </span><span><span leaf>""</span></span><span><span leaf>"  </span><span leaf><br></span><span leaf>    基于响应中XML标签计数的奖励函数。  </span><span leaf><br></span><span leaf>    "</span></span><span><span leaf>""</span></span><span leaf>    contents = [completion[0][</span><span><span leaf>"content"</span></span><span leaf>] </span><span><span leaf>for</span></span><span leaf> completion </span><span><span leaf>in</span></span><span leaf> completions]  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> [count_xml(c) </span><span><span leaf>for</span></span><span leaf> c </span><span><span leaf>in</span></span><span leaf> contents]</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>模型设置</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>model_name = </span><span><span leaf>"Qwen/Qwen2.5-1.5B-Instruct"</span></span><span leaf>  </span><span leaf><br></span><span><span leaf># 设置输出目录和运行名称  </span></span><span leaf><br></span><span leaf>output_dir = </span><span><span leaf>"outputs/Qwen-1.5B-GRPO"</span></span><span leaf>  </span><span leaf><br></span><span leaf>run_name = </span><span><span leaf>"Qwen-1.5B-GRPO-gsm8k"</span></span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>配置GRPO训练</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>training_args = GRPOConfig(  </span><span leaf><br></span><span leaf>    output_dir=output_dir,  </span><span leaf>    run_name=run_name,  </span><span leaf>    learning_rate=5e-6,  </span><span leaf>    adam_beta1=0.9,  </span><span leaf>    adam_beta2=0.99,  </span><span leaf>    weight_decay=0.1,  </span><span leaf>    warmup_ratio=0.1,  </span><span leaf>    lr_scheduler_type=</span><span><span leaf>'cosine'</span></span><span leaf>,  </span><span leaf>    logging_steps=1,  </span><span leaf>    bf16=False,  </span><span><span leaf># 设置为False，因为Colab不支持  </span></span><span leaf>    fp16=True,   </span><span><span leaf># 使用fp16以提高兼容性  </span></span><span leaf>    per_device_train_batch_size=4,  </span><span><span leaf># 增加以兼容GRPO  </span></span><span leaf>    gradient_accumulation_steps=2,  </span><span leaf>    num_generations=4,  </span><span><span leaf># 必须是per_device_train_batch_size的除数  </span></span><span leaf>    max_prompt_length=256,  </span><span leaf>    max_completion_length=512,  </span><span leaf>    num_train_epochs=1,  </span><span leaf>    save_steps=50,  </span><span leaf>    max_grad_norm=0.1,  </span><span leaf>    report_to=</span><span><span leaf>"none"</span></span><span leaf>,  </span><span leaf>    log_on_each_node=False,  </span><span leaf>)</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>配置LoRA进行参数高效微调</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span leaf>peft_config = LoraConfig(  </span><span leaf><br></span><span leaf>    r=8,  </span><span><span leaf># 从16减少以适应Colab内存  </span></span><span leaf><br></span><span leaf>    lora_alpha=32,  </span><span leaf><br></span><span leaf>    target_modules=[</span><span><span leaf>"q_proj"</span></span><span leaf>, </span><span><span leaf>"k_proj"</span></span><span leaf>, </span><span><span leaf>"v_proj"</span></span><span leaf>, </span><span><span leaf>"o_proj"</span></span><span leaf>],  </span><span><span leaf># 简化目标模块  </span></span><span leaf><br></span><span leaf>    task_type=</span><span><span leaf>"CAUSAL_LM"</span></span><span leaf>,  </span><span leaf><br></span><span leaf>    lora_dropout=0.05,  </span><span leaf><br></span><span leaf>)</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>加载并准备模型</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"加载模型：{model_name}"</span></span><span leaf>)  </span><span leaf>model = AutoModelForCausalLM.from_pretrained(  </span><span leaf>    model_name,  </span><span leaf>    torch_dtype=torch.float16,  </span><span><span leaf># 使用float16而非bfloat16  </span></span><span leaf>    device_map=</span><span><span leaf>"auto"</span></span><span leaf>,          </span><span><span leaf># 让模型自动选择最佳设备配置  </span></span><span leaf>    low_cpu_mem_usage=True,    </span><span><span leaf># 提高内存效率  </span></span><span leaf>    trust_remote_code=True     </span><span><span leaf># 新模型有时需要  </span></span><span leaf>)  </span><span><span leaf># 加载分词器  </span></span><span leaf>tokenizer = AutoTokenizer.from_pretrained(model_name)  </span><span><span leaf>if</span></span><span leaf> tokenizer.pad_token is None:  </span><span leaf>    tokenizer.pad_token = tokenizer.eos_token  </span><span><span leaf># 加载GSM8K数据集的子集  </span></span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"加载数据集..."</span></span><span leaf>)  </span><span leaf>dataset = get_gsm8k_questions(max_samples=20)  </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"数据集加载完成，共{len(dataset)}个示例"</span></span><span leaf>)</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>初始化GRPO训练器</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"初始化GRPO训练器..."</span></span><span leaf>)  </span><span leaf><br></span><span leaf><br></span><span leaf>trainer = GRPOTrainer(  </span><span leaf><br></span><span leaf>    model=model,  </span><span leaf><br></span><span leaf>    processing_class=tokenizer,  </span><span leaf><br></span><span leaf>    reward_funcs=[  </span><span leaf><br></span><span leaf>        xmlcount_reward_func,  </span><span leaf><br></span><span leaf>        soft_format_reward_func,  </span><span leaf><br></span><span leaf>        int_reward_func,  </span><span leaf><br></span><span leaf>        correctness_reward_func  </span><span leaf><br></span><span leaf>    ],  </span><span leaf><br></span><span leaf>    args=training_args,  </span><span leaf><br></span><span leaf>    train_dataset=dataset,  </span><span leaf><br></span><span leaf>    peft_config=peft_config  </span><span><span leaf># 启用LoRA进行高效微调  </span></span><span leaf><br></span><span leaf>)</span><span leaf><br></span></code></pre><h3 data-tool=mdnice编辑器><span></span><span><span leaf>运行GRPO</span></span><span></span></h3><pre data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><code><span><span leaf># 开始训练  </span></span><span leaf><br></span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"开始GRPO训练..."</span></span><span leaf>)  </span><span leaf>trainer.train()  </span><span><span leaf># 保存最终模型  </span></span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"训练完成。保存模型..."</span></span><span leaf>)  </span><span leaf>trainer.save_model()  </span><span><span leaf># 训练后测试模型  </span></span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"\n--- 测试训练后的模型 ---\n"</span></span><span leaf>)  </span><span><span leaf># 生成预测的函数  </span></span><span leaf>def generate_prediction(model, tokenizer, question, max_length=512):  </span><span leaf>    prompt = [  </span><span leaf>        {</span><span><span leaf>'role'</span></span><span leaf>: </span><span><span leaf>'system'</span></span><span leaf>, </span><span><span leaf>'content'</span></span><span leaf>: SYSTEM_PROMPT},  </span><span leaf>        {</span><span><span leaf>'role'</span></span><span leaf>: </span><span><span leaf>'user'</span></span><span leaf>, </span><span><span leaf>'content'</span></span><span leaf>: question}  </span><span leaf>    ]  </span><span leaf>    </span><span><span leaf># 格式化提示  </span></span><span leaf>    messages = tokenizer.apply_chat_template(prompt, tokenize=False, add_generation_prompt=True)  </span><span leaf>    </span><span><span leaf># 分词输入  </span></span><span leaf>    inputs = tokenizer(messages, return_tensors=</span><span><span leaf>"pt"</span></span><span leaf>).to(model.device)  </span><span leaf>    </span><span><span leaf># 生成响应  </span></span><span leaf>    with torch.no_grad():  </span><span leaf>        outputs = model.generate(  </span><span leaf>            **inputs,  </span><span leaf>            max_new_tokens=max_length,  </span><span leaf>            do_sample=False  </span><span leaf>        )  </span><span leaf>    </span><span><span leaf># 解码响应  </span></span><span leaf>    response = tokenizer.decode(outputs[0][inputs.input_ids.shape[1]:], skip_special_tokens=True)  </span><span leaf>    </span><span><span leaf>return</span></span><span leaf> response  </span><span><span leaf># 测试数据集中的几个示例  </span></span><span leaf>test_examples = dataset.select(range(3))  </span><span><span leaf>for</span></span><span leaf> i, example </span><span><span leaf>in</span></span><span leaf> enumerate(test_examples):  </span><span leaf>    question = example[</span><span><span leaf>'prompt'</span></span><span leaf>][-1][</span><span><span leaf>'content'</span></span><span leaf>]  </span><span leaf>    ground_truth = example[</span><span><span leaf>'answer'</span></span><span leaf>]  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"\n示例 {i+1}:"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"问题：{question}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"真实答案：{ground_truth}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf># 生成预测  </span></span><span leaf>    response = generate_prediction(model, tokenizer, question)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"模型响应：{response}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf># 提取答案  </span></span><span leaf>    extracted_answer = extract_xml_answer(response)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"提取的答案：{extracted_answer}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(f</span><span><span leaf>"是否正确：{extracted_answer == ground_truth}"</span></span><span leaf>)  </span><span leaf>    </span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"-"</span></span><span leaf> * 50)  </span><span><span leaf>print</span></span><span leaf>(</span><span><span leaf>"搞定！"</span></span><span leaf>)</span><span leaf><br></span></code></pre><h2 data-tool=mdnice编辑器><span data-cacheurl data-remoteid></span><span></span><span><span leaf>总结</span></span><span></span></h2><p data-tool=mdnice编辑器><span leaf>这一实现展示了GRPO的工作原理，以及如何利用它优化语言模型以适应特定格式和任务。数学问题解决任务与XML格式的结合，清晰地体现了该技术的能力。</span></p><p data-tool=mdnice编辑器><span leaf>真是一次有趣的实践！</span></p></section><blockquote><p><span leaf>作者：arjun链接：https://www.k-a.in/grpo-1B.html</span></p><p><span leaf>编辑：AI翻译、「深度学习自然语言处理」公众号润色</span></p></blockquote><section data-mpa-template=t mpa-from-tpl=t><section data-mid mpa-from-tpl=t><section data-mid mpa-from-tpl=t nodeleaf><img data-ratio=1.452 data-type=gif data-w=250 data-src="https://mmbiz.qpic.cn/mmbiz_gif/BfjzYen78aJ9jibPqC4UskObNfOib0yfKAaAc91ATL5qjKhtYfWFzia902H2WxfqrGISHpcSnSLK4jyb2qJd54w8w/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/BfjzYen78aJ9jibPqC4UskObNfOib0yfKAaAc91ATL5qjKhtYfWFzia902H2WxfqrGISHpcSnSLK4jyb2qJd54w8w/640?wx_fmt=gif"></section><section data-mid mpa-from-tpl=t><span leaf><br></span></section></section></section><h5><span><span leaf>🏴‍☠️宝藏级🏴‍☠️ 原创公众号『</span><strong><span leaf>数据STUDIO</span></strong><span leaf>』内容超级硬核。公众号以Python为核心语言，垂直于数据科学领域，包括</span></span><span><span leaf>可戳</span></span><span><span leaf>👉</span><strong><span leaf> </span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974978822768771072&amp;scene=173&amp;from_msgid=2247519294&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>Python</a></span></strong><span><strong><span><span leaf>｜</span></span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=2023684574089658370&amp;scene=173&amp;from_msgid=2247519619&amp;from_itemidx=2&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>MySQL</a></span></strong><span><strong><span><span leaf>｜</span></span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974978820940054530&amp;scene=173&amp;from_msgid=2247518366&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>数据分析</a></span></strong><span><strong><span><span leaf>｜</span></span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1974991176839544834&amp;scene=173&amp;from_msgid=2247519244&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>数据可视化</a></span></strong><span><strong><span><span leaf>｜</span></span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=1963494160565354497&amp;scene=173&amp;from_msgid=2247512171&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>机器学习与数据挖掘</a></span></strong><span><strong><span><span leaf>｜</span></span></strong></span><strong><span leaf><a href="https://mp.weixin.qq.com/mp/appmsgalbum?__biz=Mzk0OTI1OTQ2MQ==&amp;action=getalbum&amp;album_id=2318258648965644288&amp;scene=173&amp;from_msgid=2247518366&amp;from_itemidx=1&amp;count=3&amp;nolastread=1#wechat_redirect" textvalue target=_blank linktype=text data-linktype=2>爬虫</a></span></strong><span><span leaf> </span><span><span leaf>等，从入门到进阶！</span></span></span></h5><p><span><span leaf>长按👇关注- 数据STUDIO -设为星标，干货速递</span></span><span leaf><img data-ratio=0.3351851851851852 data-type=gif data-w=1080 data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI78ZgGwzt8M0xnekvrATwDWP7y4cdlwy4WOrJSUIqRfncsEYsPYM9wkQ8Gpr57zCpzia124Gb2d7icTQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI78ZgGwzt8M0xnekvrATwDWP7y4cdlwy4WOrJSUIqRfncsEYsPYM9wkQ8Gpr57zCpzia124Gb2d7icTQ/640?wx_fmt=gif"><img data-ratio=0.08703703703703704 data-type=gif data-w=1080 data-src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ickLkMzUmaxe4mdegUFLheymDmGI4OiaeeoY4K0ttDRGju4p6F7iaGfSb4H6EDCCCC9bo7KuLiblIdXQ/640?wx_fmt=gif" src="https://mmbiz.qpic.cn/mmbiz_gif/gX9JE5tiaI7ickLkMzUmaxe4mdegUFLheymDmGI4OiaeeoY4K0ttDRGju4p6F7iaGfSb4H6EDCCCC9bo7KuLiblIdXQ/640?wx_fmt=gif"></span></p><p><mp-style-type data-value=3></mp-style-type></p></div><hr><a href=https://mp.weixin.qq.com/s/EL7ZvtJS7WEeWI5P53qHDA ,target=_blank rel="noopener noreferrer">原文链接</a></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=../../../tags/fetched/ rel=tag>fetched</a></li><li class=tags__item><a class="tags__link btn" href=../../../tags/%E6%95%B0%E6%8D%AEstudio/ rel=tag>数据STUDIO</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><div class=authorbox__header><span class=authorbox__name>About Bloger</span></div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=../../../posts/2025-04/%E7%A5%9E%E7%A7%98%E6%A8%A1%E5%9E%8B%E4%B8%8A%E7%BA%BF%E4%B8%89%E5%A4%A9%E5%B7%B2%E8%A2%AB%E7%8E%A9%E7%96%AF_%E7%BD%91%E5%8F%8B%E5%8F%91%E7%8E%B0%E5%A4%A7%E9%87%8Fopenai%E7%97%95%E8%BF%B9/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>神秘模型上线三天已被玩疯 网友发现大量OpenAI痕迹</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=../../../posts/2025-04/_%E5%B1%B1%E8%A5%BF%E5%A4%A7%E5%90%8C%E8%AE%A2%E5%A9%9A%E5%BC%BA%E5%A5%B8%E6%A1%88_%E6%98%AF_%E5%A9%9A%E6%81%8B%E8%B5%84%E6%9C%AC%E4%B8%BB%E4%B9%89_%E5%B0%81%E5%BB%BA%E4%B8%BB%E4%B9%89_%E7%9A%84%E6%81%B6%E6%9E%9C/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>“山西大同订婚强奸案”是“婚恋资本主义+封建主义”的恶果</p></a></div></nav><section class=comments><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kkitown.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><input class=widget-search__field type=search placeholder=Search… name=q aria-label=Search…>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://ixxmu.github.io/></form></div><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E9%97%B2%E9%B1%BC%E4%B8%8A%E9%82%A3%E4%BA%9B%E9%80%86%E5%A4%A9%E7%9A%84%E6%B5%8B%E5%BA%8F%E4%BB%AA/>闲鱼上那些逆天的测序仪</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E8%AF%B4%E8%B5%B7%E8%BE%9B%E8%8A%B7%E8%95%BE_%E6%88%91%E6%83%B3%E8%B5%B7%E6%97%A9%E5%B9%B4%E4%B8%80%E4%BA%9B%E5%93%81%E5%91%B3_%E7%8B%AC%E7%89%B9_%E7%9A%84%E6%81%90%E6%80%96%E7%89%87/>说起辛芷蕾，我想起早年一些品味“独特”的恐怖片</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%A4%9A%E6%AC%A1%E7%94%9F%E5%AD%90%E5%90%8E_28%E5%B2%81%E5%86%9C%E6%9D%91%E6%99%BA%E9%9A%9C%E5%A5%B3%E5%AD%A9%E6%82%84%E7%84%B6%E7%A6%BB%E4%B8%96/>多次生子后，28岁农村智障女孩悄然离世</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/openai%E7%BD%95%E8%A7%81%E5%8F%91%E8%AE%BA%E6%96%87_%E6%88%91%E4%BB%AC%E6%89%BE%E5%88%B0%E4%BA%86ai%E5%B9%BB%E8%A7%89%E7%9A%84%E7%BD%AA%E9%AD%81%E7%A5%B8%E9%A6%96/>OpenAI罕见发论文：我们找到了AI幻觉的罪魁祸首</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%8D%97%E4%BA%AC%E5%8D%96%E6%B7%AB%E5%A4%B4%E7%9B%AE1_34%E4%BA%BF%E6%B8%AF%E5%85%83%E8%A2%AB%E7%91%9E%E9%93%B6%E5%8E%9F%E5%89%AF%E6%80%BB%E7%9B%91%E7%A7%81%E5%90%9E/>南京卖淫头目1.34亿港元被瑞银原副总监私吞</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../categories/duty/>Duty</a></li><li class=widget__item><a class=widget__link href=../../../categories/duty2/>Duty2</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>Tags</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=../../../tags/cnbeta/ title=Cnbeta>Cnbeta (148)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/datawhale/ title=Datawhale>Datawhale (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/drpei/ title=Drpei>Drpei (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/fetched/ title=Fetched>Fetched (755)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/githubdaily/ title=GitHubDaily>GitHubDaily (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%B8%81%E9%A6%99%E5%9B%AD/ title=丁香园>丁香园 (30)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%BA%BA%E7%89%A9/ title=人物>人物 (15)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%8D%97%E6%96%B9%E5%91%A8%E6%9C%AB/ title=南方周末>南方周末 (11)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E4%BC%97%E8%BD%AF%E4%BB%B6/ title=小众软件>小众软件 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E5%A4%A7%E5%A4%AB%E6%BC%AB%E7%94%BB/ title=小大夫漫画>小大夫漫画 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%91%E6%95%B0%E6%B4%BE/ title=少数派>少数派 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%BE%AA%E5%9B%A0%E7%BC%89%E8%8D%AF/ title=循因缉药>循因缉药 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%96%B0%E4%B9%A1%E5%9C%9F/ title=新乡土>新乡土 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%98%9F%E7%90%83%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA/ title=星球商业评论>星球商业评论 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%88%E5%85%89%E5%8D%9A%E5%AE%A2/ title=月光博客>月光博客 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%AA%E9%97%BBcode/ title=未闻Code>未闻Code (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%A7%BD%E8%BE%B9%E5%BE%80%E4%BA%8B/ title=槽边往事>槽边往事 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%AF%8F%E6%97%A5%E4%BA%BA%E7%89%A9/ title=每日人物>每日人物 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AA%E6%BD%AE%E5%B7%A5%E4%BD%9C%E5%AE%A4/ title=浪潮工作室>浪潮工作室 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AE%E4%B9%8B%E9%9D%99/ title=浮之静>浮之静 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%81%BC%E8%A7%81/ title=灼见>灼见 (8)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%86%8A%E8%A8%80%E7%86%8A%E8%AF%AD/ title=熊言熊语>熊言熊语 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E6%8A%80%E8%83%BD%E6%A0%91/ title=生信技能树>生信技能树 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E8%8F%9C%E9%B8%9F%E5%9B%A2/ title=生信菜鸟团>生信菜鸟团 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%9F%A5%E8%AF%86%E5%88%86%E5%AD%90/ title=知识分子>知识分子 (14)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%BD%91%E6%98%93%E6%95%B0%E8%AF%BB/ title=网易数读>网易数读 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E6%96%B0/ title=财新>财新 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E7%BB%8F%E4%B8%89%E5%88%86%E9%92%9F/ title=财经三分钟>财经三分钟 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B5%9B%E5%85%88%E7%94%9F/ title=赛先生>赛先生 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E9%83%91%E5%B7%9E%E6%A5%BC%E5%B8%82/ title=郑州楼市>郑州楼市 (32)</a></div><a href=../../../tags/></a></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">Social</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Facebook rel="noopener noreferrer" href=https://facebook.com/username target=_blank><svg class="widget-social__link-icon icon icon-facebook" width="24" height="24" viewBox="0 0 352 352"><path d="m0 32v288c0 17.5 14.5 32 32 32h288c17.5.0 32-14.5 32-32V32c0-17.5-14.5-32-32-32H32C14.5.0.0 14.5.0 32zm320 0v288h-83V212h41.5l6-48H237v-31c0-14 3.5-23.5 23.5-23.5h26V66c-4.4-.6-19.8-1.5-37.5-1.5-36.9.0-62 22.2-62 63.5v36h-42v48h42v108H32V32z"/></svg>
<span>Facebook</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/username target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3C20 26 16.1 39.6 16.1 54c0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1C34.9 299 76.3 312 120.8 312c144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg>
<span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Instagram rel="noopener noreferrer" href=https://www.instagram.com/username target=_blank><svg class="widget-social__link-icon icon icon-instagram" width="24" height="24" viewBox="0 0 256 256"><circle cx="193" cy="59" r="15"/><path fill-rule="evenodd" d="M101 0h54c41 0 58.4 3.9 74.5 17C256.2 37.5 256 74.8 256 97.7v60c0 26.7.0 60.4-26.5 81.4-16 13.4-33.5 16.9-74.5 16.9h-54c-41 0-57.5-3.5-74.5-16.9C1 218.9.5 186.3.1 160.5L0 155V97.7c0-23-.2-60.2 26.5-80.7C45 2 60 0 101 0zm4.9 23h44.3c45.8.0 58.3 3.5 70.3 17.5 11.8 13.2 12 30.1 12.5 62.9V156c.2 20.8.3 45.8-12.5 59.5-12 14-24.5 17.5-70.3 17.5h-44.3c-45.9.0-57.3-3.5-70.4-17.5-12.2-13-12.3-36.5-12.4-56.7v-55.6c.4-32.6.7-49.6 12.4-62.7C48 26.5 60 23 105.9 23zm19.6 144.5a42 42 0 100-84 42 42 0 000 84zm0 22.5a64.5 64.5.0 100-129 64.5 64.5.0 000 129z"/></svg>
<span>Instagram</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 文字轨迹.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=../../../js/menu.js></script><script src=../../../js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>