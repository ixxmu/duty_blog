<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 - 文字轨迹</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://ixxmu.github.io/posts/2025-02/%E9%A9%BE%E9%A9%AD_deep_research_%E4%BD%A0%E5%BF%85%E9%A1%BB%E7%9F%A5%E9%81%93%E7%9A%84_100_%E4%BB%B6%E4%BA%8B_%E4%B8%80%E6%AC%A1%E6%80%A7%E6%9E%84%E5%BB%BA%E5%87%BA%E4%BD%A0%E7%9A%84_deep_research_%E4%B8%AA%E4%BA%BA%E7%9F%A5%E8%AF%86%E4%BD%93%E7%B3%BB/"><meta property="og:site_name" content="文字轨迹"><meta property="og:title" content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系"><meta property="og:description" content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 by Howie和小能熊 deep research 很可能（probable,60%--80%概率）是自chatgpt之后第二个革命性AI技术。因为它真正改变了脑力劳动者的生产力格局；你对 deep research 的态度在本质上取决于你对技术本质的判断，对技术的敏感度与洞察；我目前对“deep research是革命性技术”的置信度是80%，如果相反证据出现，我自然会贝叶斯更新我的推断；在相反证据出现之前，我建议你对这项技术予以足够重视。能花 100 小时在这上面，就别只花 99 小时；对改变了生产力格局的deep research，你的个人知识体系越全面，理解就越深，使用就越好。通过这篇文章，我把自己脑子里关于 deep research 的知识和经验全部敲出来，希望帮你更全面深入地理解 deep research 到底是什么，为什么重要，如何使用，如何改变生命；why2025年是agent之年。根据openai的agi分级框架，chatbot/知识模型是L1 agi，reasoning model/推理模型是L2 agi，而agent/任务模型是L3 agi；今年，openai 已经陆续推出chatgpt tasks、operator 和deep research 这三个 agents。tasks 是基础的任务提醒，operator 是直接操作浏览器，与真实世界互动，deep research是帮专业人士做研究；前两个几乎无人问津。但是，对于 deep research，如果你不是干体力活的，真的没理由不关注一下，除非你端的是铁饭碗，而且是最稳的那种🤣；whatdeep research（深度研究）是一个功能，一个模型，一个以“研究”为专业的AI agent（智能体/代理）。openai的官方广告语是：你的个人研究助理；最先推出deep research功能的是 google gemini，发布于 2024 年 12 月中旬；然后是openai（25 年 2 月），紧接着是 perplexity；grok3 推出的是 deep search（ai 搜索，更接近推理模型版本的 chatgpt search），不是 deep research（本质是 ai agent）；google deep research 底层模型是gemini 1."><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-27T16:47:24+00:00"><meta property="article:modified_time" content="2025-02-27T16:47:24+00:00"><meta property="article:tag" content="Fetched"><meta property="article:tag" content="Howie和小能熊"><meta itemprop=name content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系"><meta itemprop=description content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 by Howie和小能熊 deep research 很可能（probable,60%--80%概率）是自chatgpt之后第二个革命性AI技术。因为它真正改变了脑力劳动者的生产力格局；你对 deep research 的态度在本质上取决于你对技术本质的判断，对技术的敏感度与洞察；我目前对“deep research是革命性技术”的置信度是80%，如果相反证据出现，我自然会贝叶斯更新我的推断；在相反证据出现之前，我建议你对这项技术予以足够重视。能花 100 小时在这上面，就别只花 99 小时；对改变了生产力格局的deep research，你的个人知识体系越全面，理解就越深，使用就越好。通过这篇文章，我把自己脑子里关于 deep research 的知识和经验全部敲出来，希望帮你更全面深入地理解 deep research 到底是什么，为什么重要，如何使用，如何改变生命；why2025年是agent之年。根据openai的agi分级框架，chatbot/知识模型是L1 agi，reasoning model/推理模型是L2 agi，而agent/任务模型是L3 agi；今年，openai 已经陆续推出chatgpt tasks、operator 和deep research 这三个 agents。tasks 是基础的任务提醒，operator 是直接操作浏览器，与真实世界互动，deep research是帮专业人士做研究；前两个几乎无人问津。但是，对于 deep research，如果你不是干体力活的，真的没理由不关注一下，除非你端的是铁饭碗，而且是最稳的那种🤣；whatdeep research（深度研究）是一个功能，一个模型，一个以“研究”为专业的AI agent（智能体/代理）。openai的官方广告语是：你的个人研究助理；最先推出deep research功能的是 google gemini，发布于 2024 年 12 月中旬；然后是openai（25 年 2 月），紧接着是 perplexity；grok3 推出的是 deep search（ai 搜索，更接近推理模型版本的 chatgpt search），不是 deep research（本质是 ai agent）；google deep research 底层模型是gemini 1."><meta itemprop=datePublished content="2025-02-27T16:47:24+00:00"><meta itemprop=dateModified content="2025-02-27T16:47:24+00:00"><meta itemprop=wordCount content="417"><meta itemprop=keywords content="Fetched,Howie和小能熊"><meta name=twitter:card content="summary"><meta name=twitter:title content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系"><meta name=twitter:description content="驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 by Howie和小能熊 deep research 很可能（probable,60%--80%概率）是自chatgpt之后第二个革命性AI技术。因为它真正改变了脑力劳动者的生产力格局；你对 deep research 的态度在本质上取决于你对技术本质的判断，对技术的敏感度与洞察；我目前对“deep research是革命性技术”的置信度是80%，如果相反证据出现，我自然会贝叶斯更新我的推断；在相反证据出现之前，我建议你对这项技术予以足够重视。能花 100 小时在这上面，就别只花 99 小时；对改变了生产力格局的deep research，你的个人知识体系越全面，理解就越深，使用就越好。通过这篇文章，我把自己脑子里关于 deep research 的知识和经验全部敲出来，希望帮你更全面深入地理解 deep research 到底是什么，为什么重要，如何使用，如何改变生命；why2025年是agent之年。根据openai的agi分级框架，chatbot/知识模型是L1 agi，reasoning model/推理模型是L2 agi，而agent/任务模型是L3 agi；今年，openai 已经陆续推出chatgpt tasks、operator 和deep research 这三个 agents。tasks 是基础的任务提醒，operator 是直接操作浏览器，与真实世界互动，deep research是帮专业人士做研究；前两个几乎无人问津。但是，对于 deep research，如果你不是干体力活的，真的没理由不关注一下，除非你端的是铁饭碗，而且是最稳的那种🤣；whatdeep research（深度研究）是一个功能，一个模型，一个以“研究”为专业的AI agent（智能体/代理）。openai的官方广告语是：你的个人研究助理；最先推出deep research功能的是 google gemini，发布于 2024 年 12 月中旬；然后是openai（25 年 2 月），紧接着是 perplexity；grok3 推出的是 deep search（ai 搜索，更接近推理模型版本的 chatgpt search），不是 deep research（本质是 ai agent）；google deep research 底层模型是gemini 1."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../css/style.css><link rel=stylesheet href=../../../css/custom.css><link rel="shortcut icon" href=../../../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../ title=文字轨迹 rel=home><div class="logo__item logo__text"><div class=logo__title>文字轨迹</div><div class=logo__tagline>故事流淌过的地方</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../posts/><span class=menu__text>文章</span></a></li><li class=menu__item><a class=menu__link href=../../../tags/><span class=menu__text>标签</span></a></li><li class=menu__item><a class=menu__link href=../../../about/><span class=menu__text>关于</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><meta name=referrer content="never"><h1 class=post__title>驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2025-02-27T16:47:24Z>2025-02-27</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../categories/duty/ rel=category>Duty</a></span></div><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 16 16"><path d="M8 1c2 0 3.5 2 3.5 4.5S10 9 10 9c3 1 4 2 4 6H2c0-4 1-5 4-6 0 0-1.5-1-1.5-3.5S6 1 8 1"/></svg><span class=meta__text>Bloger</span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#驾驭-deep-research你必须知道的-100-件事一次性构建出你的-deep-research-个人知识体系-by-howie和小能熊>驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 by Howie和小能熊</a></li></ul></nav></div></div><div class="content post__content clearfix"><h2 id=驾驭-deep-research你必须知道的-100-件事一次性构建出你的-deep-research-个人知识体系-by-howie和小能熊>驾驭 deep research，你必须知道的 100 件事｜一次性构建出你的 deep research 个人知识体系 by Howie和小能熊</h2><div><section data-tool=mdnice编辑器 data-website=https://www.mdnice.com><ul><li><section><span leaf>deep research 很可能（probable,60%--80%概率）是自chatgpt之后第二个</span><strong><span leaf>革命性AI技术</span></strong><span leaf>。因为它真正改变了</span><strong><span leaf>脑力劳动者的生产力格局</span></strong><span leaf>；</span></section></li><li><section><span leaf>你对 deep research 的态度在本质上取决于你</span><strong><span leaf>对技术本质的判断</span></strong><span leaf>，对技术的敏感度与洞察；</span></section></li><li><section><span leaf>我目前对“deep research是革命性技术”的置信度是80%，如果相反证据出现，我自然会</span><strong><span leaf>贝叶斯更新</span></strong><span leaf>我的推断；在相反证据出现之前，我建议你对这项技术予以足够重视。</span><strong><span leaf>能花 100 小时在这上面，就别只花 99 小时</span></strong><span leaf>；</span></section></li><li><section><span leaf>对改变了生产力格局的deep research，你的</span><strong><span leaf>个人知识体系</span></strong><span leaf>越全面，理解就越深，使用就越好。通过这篇文章，我把自己脑子里关于 deep research 的知识和经验全部敲出来，希望帮你更全面深入地理解 deep research 到底</span><strong><span leaf>是什么</span></strong><span leaf>，</span><strong><span leaf>为什么</span></strong><span leaf>重要，</span><strong><span leaf>如何</span></strong><span leaf>使用，</span><strong><span leaf>如何</span></strong><span leaf>改变生命；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3qjSahue9aswneNXb2CH42EH8ibQt9pWf3f7dlF0wf8cpI9Hhp7LkvZQ/640?wx_fmt=png&amp;from=appmsg" data-ratio=0.42592592592592593 data-type=png data-w=1080 data-imgfileid=100009883 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3qjSahue9aswneNXb2CH42EH8ibQt9pWf3f7dlF0wf8cpI9Hhp7LkvZQ/640?wx_fmt=png&amp;from=appmsg"></span></figure><h2 data-tool=mdnice编辑器><span></span><span leaf>why</span></h2><ul><li><section><span leaf>2025年是agent之年。根据</span><strong><span leaf>openai的agi分级框架</span></strong><span leaf>，chatbot/知识模型是L1 agi，reasoning model/推理模型是L2 agi，而agent/任务模型是L3 agi；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT35DarXhaYKcpE8OxadUic8M6Re5y1NnAhy7Vv7EEKwFVP15pCZL3LGhw/640?wx_fmt=png&amp;from=appmsg" data-ratio=0.4666666666666667 data-type=png data-w=1080 data-imgfileid=100009880 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT35DarXhaYKcpE8OxadUic8M6Re5y1NnAhy7Vv7EEKwFVP15pCZL3LGhw/640?wx_fmt=png&amp;from=appmsg"></span></figure><ul><li><section><span leaf>今年，openai 已经陆续推出chatgpt tasks、operator 和deep research 这</span><strong><span leaf>三个 agents</span></strong><span leaf>。tasks 是基础的任务提醒，operator 是直接操作浏览器，与真实世界互动，deep research是帮专业人士做研究；</span></section></li><li><section><span leaf>前两个几乎无人问津。但是，对于 deep research，如果你不是干</span><strong><span leaf>体力活</span></strong><span leaf>的，真的没理由不关注一下，除非你端的是</span><strong><span leaf>铁饭碗</span></strong><span leaf>，而且是最稳的那种🤣；</span></section></li></ul><h2 data-tool=mdnice编辑器><span></span><span leaf>what</span></h2><ul><li><section><span leaf>deep research（深度研究）是一个功能，一个模型，一个以“研究”为专业的</span><strong><span leaf>AI agent（智能体/代理）</span></strong><span leaf>。openai的官方广告语是：你的个人研究助理；</span></section></li><li><section><span leaf>最先推出deep research功能的是 google gemini，发布于 </span><strong><span leaf>2024 年 12 月</span></strong><span leaf>中旬；然后是openai（25 年 2 月），紧接着是 perplexity；</span></section></li><li><section><span leaf>grok3 推出的是 </span><strong><span leaf>deep search</span></strong><span leaf>（ai 搜索，更接近推理模型版本的 chatgpt search），不是 deep research（本质是 ai agent）；</span></section></li><li><section><span leaf>google deep research </span><strong><span leaf>底层模型</span></strong><span leaf>是gemini 1.5 pro，全名叫“Gemini 1.5 Pro with Deep Research”。虽然 google在搜索上有近 30 年技术积累，但由于模型基础性能拉跨，导致输出结果和openai deep research 有数量级差距；</span></section></li><li><section><span leaf>google deep research 会在用户提出问题后自动制定</span><strong><span leaf>多步骤研究计划</span></strong><span leaf>。系统先生成一个分步研究方案供用户审核，可根据需要修改，然后用户点击“Start research”开始执行。获得授权后，Gemini 会像人类研究者一样反复执行 </span><strong><span leaf>“搜索-阅读-分析”循环</span></strong><span leaf>：利用 google 搜索查找相关内容，读取网页获取信息，再根据新发现调整搜索策略。这一过程会持续数分钟，期间 gemini 持续完善对主题的理解，发起多轮检索和推理，以确保覆盖话题的各个方面。整个浏览和思考过程在后台自动完成，无需用户干预。基本上各家的 deep research 都是这个流程。</span></section></li><li><section><span leaf>google deep research的特点是</span><strong><span leaf>在搜索上大力</span></strong><span leaf>（结果没有奇迹）：通常浏览上百个网站，阅读上千个网页，提供的研究报告带上百个参考文献。很唬人，不明觉厉。但是，openai deep research 出来后，这一套就不灵了，经不住内容质量上的鲜明对比；</span></section></li><li><section><span leaf>perplexity 推出的 deep research 基本属于蹭热点、找存在感，相当于“挂羊头卖狗肉”，质量差到没人用，</span><strong><span leaf>不建议浪费时间</span></strong><span leaf>；</span></section></li><li><section><span leaf>google ai 会员 20 美金/月，支持 6 人家庭共享，deep research 不限量；perplexity ai 会员 20 美金/月，也不限量；openai 20 美金的 plus会员，每月 10 次限额；</span><strong><span leaf>价格差异</span></strong><span leaf>一方面是成本差异巨大，一方面是质量差异带来底气；</span></section></li><li><section><span leaf>deep research 本质上在做一件事：</span><strong><span leaf>主题研究</span></strong><span leaf>。这件事对本科生来说有涉及，对研究生来说是关键能力，但是，大多数人做不好。AI 在这件事上展现出的实力，让人类用户震惊、感慨，思考自己</span><strong><span leaf>智力活动的价值</span></strong><span leaf>（包括形而上的意义价值，更包括形而下的经济价值）（人的智力活动当然有价值，但必须重新调整自身智力活动的定位，只能做到 ai 能做到的程度，那就危险）；</span></section></li><li><section><span leaf>决定deep research 效果的，不是“如何做研究”的步骤方法流程技巧（模型的系统指令很简单，o3的基础智能极强，不需要你教它如何做研究），而是</span><strong><span leaf>底层的 reasoning model</span></strong><span leaf>。这也是为什么 o3 驱动的 deep research 效果惊人；</span></section></li></ul><h3 data-tool=mdnice编辑器><span></span><span leaf>openai deep research</span><span></span></h3><ul><li><section><span leaf>openai deep research 是 2025 年 2 月 3 号推出的，开始时是 200 美金/月的 pro 用户独享。pro 用户独占使用 3 周后，openai 把这个功能普及到 plus 用户，后续会普及到</span><strong><span leaf>免费用户</span></strong><span leaf>；</span></section></li><li><section><span leaf>deep research 发布后，由于是pro独占，我思考了 5 分钟，然后升级到 200美金 pro 会员。今天，使用了接近一个月后，我可以这么说：</span><strong><span leaf>除非</span></strong><span leaf>我娃没钱吃饭了，否则我会一直用pro（我自己没钱吃饭也会开pro）；</span></section></li><li><section><span leaf>使用 chatgpt pro 的</span><strong><span leaf>难度不低</span></strong><span leaf>，不是200 美金问题（舍不得在“软件”上花钱的人，在其他地方花钱可能很豪气），而是视角问题（到底是软件？是工具？还是待你整合到工作流、为你创造价值、甚至金钱价值的智能体？），以及网络技术问题（openai 无良降智）；</span></section></li><li><section><span leaf>使用 pro，需要极高的 </span><strong><span leaf>agency（能动性）</span></strong><span leaf>：要有与openai斗智斗勇永不妥协的能力和意愿，要心态开放到至少开一个月试试智能时代全新工作学习体验；</span></section></li><li><section><span leaf>pro用户</span><strong><span leaf>每月限额</span></strong><span leaf> 120 次，plus 用户每月 10 次，免费用户每月 2 次（暂估）；</span></section></li><li><section><span leaf>pro、plus和免费用户使用的 deep research 功能是一样的，只有限额的次数区别，</span><strong><span leaf>没有性能区别</span></strong><span leaf>；</span></section></li><li><section><strong><span leaf>每月限额</span></strong><span leaf>并非以自然月份划分，而是以你升级会员的具体日期划分；</span></section></li><li><section><span leaf>openai deep research的</span><strong><span leaf>底层模型</span></strong><span leaf>是尚未发布的满血版 o3，是针对互联网浏览特别微调的一个特殊版本；</span></section></li><li><section><span leaf>我的 deep research 的总结是：o3 </span><strong><span leaf>reasoning model + search</span></strong><span leaf> = deep research magic。与常规的 ai 搜索不同，deep research 的重点是深度，而非时效。你提出研究需求，deep research 会帮你把互联网</span><strong><span leaf>翻个底朝天</span></strong><span leaf>，而且吃透这些材料，为你私人定制研究报告。</span></section></li><li><section><span leaf>口诀：</span><strong><span leaf>快问快答</span></strong><span leaf>，用ai搜索；系统调研，用 deep research；</span></section></li><li><section><span leaf>我把 ai 搜索分为三个层级。L1 是 </span><strong><span leaf>gpt-4o+search</span></strong><span leaf>，搜索信息、综合多个信息源内容，给出一个整体回答；level 2 </span><strong><span leaf>o3-mini+search</span></strong><span leaf>，加上了推理能力，如果问题是需要思考的，需要多步骤的推理过程，最终给出一个权衡、分析后的结果，就用o3-mini；level 3 </span><strong><span leaf>o3+deep research</span></strong><span leaf>，难度提高到研究级别，输出结果为上万字的研究报告；</span></section></li><li><section><span leaf>换一个时间角度：如果一个问题是人工用</span><strong><span leaf>几分钟</span></strong><span leaf>可以解决的，用gpt-4o+search 就够了；如果一个问题是人工用</span><strong><span leaf>几十分钟</span></strong><span leaf>可以解决的，用o3-mini+search；如果一个问题是人工用</span><strong><span leaf>几个小时、甚至几天</span></strong><span leaf>才能解决的，用 deep research；</span></section></li><li><section><span leaf>在</span><strong><span leaf>信息来源</span></strong><span leaf>上，deep research 可访问所有公开网页，包括网上的图片、pdf、文档，也支持你上传自己本地的图片、文档；</span></section></li></ul><h2 data-tool=mdnice编辑器><span></span><span leaf>how</span></h2><ul><li><section><span leaf>既然限额是20或120次/月，那么，</span><strong><span leaf>怎么就算“一次”</span></strong><span leaf>？只要有研究进度条开始走动，就正式启动了deep research阶段，算一次研究；</span></section></li><li><section><strong><span leaf>一次deep research流程</span></strong><span leaf>分为两个阶段：对齐需求阶段，正式研究阶段；</span></section></li><li><section><span leaf>你提出研究需求，chatgpt 会重述它的理解，并针对不明确、表达模糊、你没想到的地方提出问题（clarifying questions），你需要一一确认；这个“</span><strong><span leaf>对齐需求阶段</span></strong><span leaf>”可能会重复一轮或多轮；</span></section></li><li><section><strong><span leaf>可惜的事</span></strong><span leaf>：即使不对比研究阶段，只是需求对齐阶段，人类往往就和 deep research 这样的 ai 拉开了差距；</span></section></li><li><section><span leaf>对齐需求阶段使用的不是 o3 模型，而是你在 model picker（</span><strong><span leaf>模型选项卡</span></strong><span leaf>）里面选择的模型；一般情况下，建议你选择 o1 模型，其次是 gpt-4o 模型；实际差异不大，因为正式研究都是o3 模型，而在理解需求这种简单任务上区别不大；</span></section></li><li><section><span leaf>你可以在提需求时</span><strong><span leaf>上传自己的资料</span></strong><span leaf>：word、PDF、md、图片，作为deep research 的参考材料；</span></section></li><li><section><span leaf>正式研究开始后，</span><strong><span leaf>一般耗时</span></strong><span leaf> 5～30 分钟，长度根据任务难度而变化。我目前研究时长最长的，是让 deep research 用一个报告解读芒格 100 模型，耗时 36 分钟，报告 5.7 万字，质量惊人；</span></section></li><li><section><span leaf>对 deep research 会话中，页面右侧有一个类似 </span><strong><span leaf>CoT 的侧边栏</span></strong><span leaf>，展示了本次研究的全部信息源、以及具体的分步骤研究过程。就好像你站在一个真人研究员身后看他做研究：思考——搜索——阅读——思考——搜索……</span></section></li><li><section><span leaf>deep research 本质是 agent，deep research 任务是</span><strong><span leaf>异步任务</span></strong><span leaf>（对比之下，chat 是同步活动）；你交代完之后，模型开始干活，你该干嘛干嘛，网页可以关掉，app 可以退出，研究在服务器远程运行，完成后会推送给你；</span></section></li><li><section><span leaf>报告生成后，你可以在原始对话中</span><strong><span leaf>继续提出新的研究需求</span></strong><span leaf>，模型会保持对之前研究的记忆，但本质上是一次新的研究（不会在原始报告上修改，会重新生成新的研究报告）；</span></section></li><li><section><span leaf>研究报告除了文字之外，还会插入表格、图片、图表等促进理解的内容形式；未来，你会看到AI 自动生成的数据可视化、示意图等；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3oaicomM8qTIab7R0eeZGMJbhUcDoaSn9vKjgzNdK5R7pmERbFvkom2w/640?wx_fmt=png&amp;from=appmsg" data-ratio=0.6092592592592593 data-type=png data-w=1080 data-imgfileid=100009882 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3oaicomM8qTIab7R0eeZGMJbhUcDoaSn9vKjgzNdK5R7pmERbFvkom2w/640?wx_fmt=png&amp;from=appmsg"></span></figure><ul><li><section><span leaf>deep research 对</span><strong><span leaf>参考文献的引用，精确到“行”</span></strong><span leaf>。点击报告内的参考文献链接，原始网页上实际被模型做了高光标记。目前受限于浏览器，一般人看不到这个精确引用而已；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3y60ysanMoN1vVu5x46b3gGg8wGmLLsxn6nebhhbQBaFG2QPncMiawmA/640?wx_fmt=png&amp;from=appmsg" data-ratio=0.4583333333333333 data-type=png data-w=1080 data-imgfileid=100009881 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3y60ysanMoN1vVu5x46b3gGg8wGmLLsxn6nebhhbQBaFG2QPncMiawmA/640?wx_fmt=png&amp;from=appmsg"></span></figure><ul><li><section><span leaf>deep research 精确引用这一点，在</span><strong><span leaf>论文写作</span></strong><span leaf>等场合堪称大杀器；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3dfW6Ze2UZozIBytP40SVgWFAk8sEE8UNib0iby9BSw6ickib6ZpPRbQVfg/640?wx_fmt=png&amp;from=appmsg" data-ratio=0.2574074074074074 data-type=png data-w=1080 data-imgfileid=100009879 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3dfW6Ze2UZozIBytP40SVgWFAk8sEE8UNib0iby9BSw6ickib6ZpPRbQVfg/640?wx_fmt=png&amp;from=appmsg"></span></figure><ul><li><section><span leaf>openai 官方一再强调，即使 o3 模型很强，但 deep research </span><strong><span leaf>仍然可能有幻觉</span></strong><span leaf>，因为模型目前不会主动去辨别网络上信息源的真伪，仍然受到“garbage in, garbage out”法则的制约；</span></section></li><li><section><span leaf>但是，主动辨别信息源质量高低、信息真伪，对推理模型来讲这本身不难（truth-grounding，</span><strong><span leaf>事实接地技术</span></strong><span leaf>），会在功能迭代中解决；</span></section></li><li><section><span leaf>正因为如此，你可能需要限定模型搜索使用的</span><strong><span leaf>语言和资料范围</span></strong><span leaf>：只有英文关键词搜索，只采纳英文资料。如果这个主题是国际范围有关注的，你应该这么做；</span></section></li><li><section><span leaf>目前的</span><strong><span leaf>一大局限</span></strong><span leaf>是无法接入付费资源（数据库、学术期刊）和私人知识库等非公开信息，但这可以解决；</span></section></li><li><section><span leaf>但是，如果你研究的主题只有</span><strong><span leaf>中文资料</span></strong><span leaf>，你或许应该限定模型只用中文关键词搜索，只采纳中文资料；</span></section></li><li><section><span leaf>研究报告数万字，直接在 chatgpt 页面</span><strong><span leaf>阅读体验</span></strong><span leaf>并非最好，无法高光划线，无法记笔记。最简单的方式是剪藏到 readwise reader 这样的阅读器软件，另一种方式是使用“chatgpt to markdown”chrome 插件导出为 md 文档，然后用 typora 转换为任意格式，例如可以导入微信读书 app 的 epub；</span></section></li><li><section><span leaf>我做了不少 deep research 测试，我的结论是</span><strong><span leaf>研究报告的质量</span></strong><span leaf>(内容丰富度、研究广度、信息质量、报告结构和语言清晰、参考文献等)超越了 99% 的人类产出，有人调研行业专家的反馈是每份报告让专家亲自来做的话耗时至少 10 小时，但这个数字可能保守了；我认为更接近的表述是 “就像有一个专业研究员为你工作了一周，然后写出完整分析报告”；</span></section></li><li><section><span leaf>相对于人类产出的</span><strong><span leaf>传统知识媒介</span></strong><span leaf>（文章、书籍、podcast 和视频），deep research 报告的信息密度、结构化程度、质量、丰富度、个性化程度，都碾压传统媒介一个数量级；一个顺理成章的结论：多读 deep research 报告，尽可能多读；</span></section></li><li><section><span leaf>举个例子，我昨天做了一次 deep research，发现它在一个主题的研究质量上竟然比 steven pinker 在《理性》那本书里面同主题内容的质量还高。不是 steven pinker 不行，而是他也是人，</span><strong><span leaf>人类认知的局限性</span></strong><span leaf>导致他也看不到只有 deep research 才看到的东西；</span></section></li><li><section><span leaf>deep research 的一个</span><strong><span leaf>典型应用场景</span></strong><span leaf>：针对书籍生成导读报告；不取代原书整本书阅读，但绝对会让你更快更好地读透那些值得阅读 5678 遍的好书；</span></section></li><li><section><span leaf>从今以后，</span><strong><span leaf>读完任何一本值得读的书</span></strong><span leaf>，都要 deep research 一下！20 万字的一本书，假设阅读 6 小时（每天 1 小时一周读完），然后 deep research 一下，用半天研究阅读报告，整理 logseq 笔记，然后再和chatgpt 多轮对话…… 10个小时的效果，可能抵得上以前几十甚至上百个小时……满打满算，生命被延长了一大截；</span></section></li><li><section><span leaf>我在书籍解读上的测试，使用英文信息源 vs 中文信息源，原理上 garbage in garbage out, 结果上“差之毫厘，谬以千里”。以 </span><strong><span leaf>《百年孤独》</span></strong><span leaf> 深度研究报告为实例，同样的 prompt，同样的 o3 模型，同样的研究主题，只有一个区别：一次研究指定全部用英文信息源，另一次研究指定全部用中文信息源，其中一个不忍卒读；</span></section></li><li><section><span leaf>deep research 运行在人类认知能力金字塔的</span><strong><span leaf>信息综合</span></strong><span leaf>层面：不需要创造力，不需要创新，不需要创意写作，就是非常朴实地、把有价值的信息找出来，全部读完，然后用结构化、清晰有序地方式把海量高价值信息整合成一篇高质量研究报告；</span></section></li></ul><figure data-tool=mdnice编辑器><span leaf><img data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3sdibwTfhG033I2ibw36auUq9tK2PYsO3K3AKuOvEuR3114Sr7wD6KWyg/640?wx_fmt=png&amp;from=appmsg" alt="我基于benjamin bloom理论的升级改造" data-ratio=0.8805555555555555 data-type=png data-w=1080 data-imgfileid=100009884 src="https://mmbiz.qpic.cn/sz_mmbiz_png/Wp9RhwK45WicQiaHteKT9k9cEiaGfcxwHT3sdibwTfhG033I2ibw36auUq9tK2PYsO3K3AKuOvEuR3114Sr7wD6KWyg/640?wx_fmt=png&amp;from=appmsg"></span><figcaption><span leaf>我基于benjamin bloom理论的升级改造</span></figcaption></figure><ul><li><section><span leaf>这件事难度不高，从“信息综合”的要求层次来讲，按理说研究生水平的人就能干；但是，充分展示了当 AI 达到一个智力水平后，发挥出人类无法企及的</span><strong><span leaf>信息获取、加工处理等算力优势</span></strong><span leaf>时，会有多么恐怖。从这个层面会看到，deep research 只要在信息综合层面超过一个临界点，就会让人类同等层级的智力劳动（达不到创造级别的）价值暴跌；</span></section></li><li><section><span leaf>deep research 的 </span><strong><span leaf>system prompt</span></strong><span leaf> 其实很简单，只有两个工具：browser 浏览器和 Python。browser 只做三件事：搜索、阅读、引用。Python 只做数据处理、表格呈现。但是，当底层模型的语言能录与逻辑推理能力足够强大时（如 o3），只需要极简的认知活动（搜索-阅读-引用，不需要显式定义复杂的主题研究流程），就能制造人类无法企及的出色结果；</span></section></li><li><section><span leaf>deep research 的威力发挥，需要充分</span><strong><span leaf>运用你的想象力</span></strong><span leaf>，以及你在自身领域的专业知识。发现随着想象力的打开，一手经验的积累，deep research 的强大变得越来越显著；</span></section></li><li><section><span leaf>19名</span><strong><span leaf>领域专家</span></strong><span leaf>对 openai 和 google deep research 报告的评价结果：有 7 人（37%） 认为 openai deep research 达到了“经验丰富的专业人士”水平；有 10 人（52%） 认为 openai deep research 产出的报告至少需要花费自己 10 小时以上才能完成；</span></section></li></ul><h2 data-tool=mdnice编辑器><span></span><span leaf>how good</span></h2><ul><li><section><strong><span leaf>deep research, is the new search</span></strong><span leaf>。 deep research，会和 google 一样，从一个名词变成一个动词：“有问题？deep research 一下！”。背后的本质，是最优质的智能成为一种廉价、人人唾手可得的资源（智能时代的本质）；</span></section></li><li><section><span leaf>deep research，作为 ai agent 的杀手级应用，是直接提供产出，直接对标人类生产力和价值创造活动，是普通人应当战略重视、充分掌握的最强生产力技术。这也是 openai 首次在 blog 里面用</span><strong><span leaf>预期经济价值、人类专家工时</span></strong><span leaf>来衡量新功能，这个改变很说明问题；</span></section></li><li><section><span leaf>openai在agent方面的愿景是打造 </span><strong><span leaf>“超级助理”</span></strong><span leaf>，能胜任人类专家才能完成的分析研究工作。很有可能这件事在2025年底就会发生（勿谓言之不预）;</span></section></li><li><section><span leaf>所以，</span><strong><span leaf>每天</span></strong><span leaf>，deep research一下；每天，阅读一份 deep research 报告或同主题内容（例如本文）。</span></section></li></ul><blockquote><p><span leaf>通过这篇文章，我把自己脑子里关于 deep research 的知识和经验全部敲出来了。</span></p><p><span leaf>肯定有没想到的地方，欢迎你在评论区提问，在问答中我们来补充完善，让这篇文章帮助到更多的人。</span></p></blockquote></section><p><mp-style-type data-value=3></mp-style-type></p></div><hr><a href=https://mp.weixin.qq.com/s/B6LrusPBE9YXhQbctZle1g ,target=_blank rel="noopener noreferrer">原文链接</a></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=../../../tags/fetched/ rel=tag>fetched</a></li><li class=tags__item><a class="tags__link btn" href=../../../tags/howie%E5%92%8C%E5%B0%8F%E8%83%BD%E7%86%8A/ rel=tag>Howie和小能熊</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><div class=authorbox__header><span class=authorbox__name>About Bloger</span></div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=../../../posts/2025-02/%E9%9B%B6%E5%9F%BA%E7%A1%80%E5%85%A5%E9%97%A8_deepseek%E5%BE%AE%E8%B0%83%E7%9A%84%E8%AF%84%E6%B5%8B%E6%95%99%E7%A8%8B%E6%9D%A5%E4%BA%86_/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>零基础入门：DeepSeek微调的评测教程来了！</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=../../../posts/2025-02/%E6%88%91_%E4%BA%8C%E6%9C%AC%E5%87%BA%E8%BA%AB_%E6%83%B3%E5%81%9A%E5%AD%A6%E6%9C%AF/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>我，二本出身，想做学术</p></a></div></nav><section class=comments><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kkitown.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><input class=widget-search__field type=search placeholder=Search… name=q aria-label=Search…>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://ixxmu.github.io/></form></div><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E9%97%B2%E9%B1%BC%E4%B8%8A%E9%82%A3%E4%BA%9B%E9%80%86%E5%A4%A9%E7%9A%84%E6%B5%8B%E5%BA%8F%E4%BB%AA/>闲鱼上那些逆天的测序仪</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E8%AF%B4%E8%B5%B7%E8%BE%9B%E8%8A%B7%E8%95%BE_%E6%88%91%E6%83%B3%E8%B5%B7%E6%97%A9%E5%B9%B4%E4%B8%80%E4%BA%9B%E5%93%81%E5%91%B3_%E7%8B%AC%E7%89%B9_%E7%9A%84%E6%81%90%E6%80%96%E7%89%87/>说起辛芷蕾，我想起早年一些品味“独特”的恐怖片</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%A4%9A%E6%AC%A1%E7%94%9F%E5%AD%90%E5%90%8E_28%E5%B2%81%E5%86%9C%E6%9D%91%E6%99%BA%E9%9A%9C%E5%A5%B3%E5%AD%A9%E6%82%84%E7%84%B6%E7%A6%BB%E4%B8%96/>多次生子后，28岁农村智障女孩悄然离世</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/openai%E7%BD%95%E8%A7%81%E5%8F%91%E8%AE%BA%E6%96%87_%E6%88%91%E4%BB%AC%E6%89%BE%E5%88%B0%E4%BA%86ai%E5%B9%BB%E8%A7%89%E7%9A%84%E7%BD%AA%E9%AD%81%E7%A5%B8%E9%A6%96/>OpenAI罕见发论文：我们找到了AI幻觉的罪魁祸首</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%8D%97%E4%BA%AC%E5%8D%96%E6%B7%AB%E5%A4%B4%E7%9B%AE1_34%E4%BA%BF%E6%B8%AF%E5%85%83%E8%A2%AB%E7%91%9E%E9%93%B6%E5%8E%9F%E5%89%AF%E6%80%BB%E7%9B%91%E7%A7%81%E5%90%9E/>南京卖淫头目1.34亿港元被瑞银原副总监私吞</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../categories/duty/>Duty</a></li><li class=widget__item><a class=widget__link href=../../../categories/duty2/>Duty2</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>Tags</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=../../../tags/cnbeta/ title=Cnbeta>Cnbeta (148)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/datawhale/ title=Datawhale>Datawhale (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/drpei/ title=Drpei>Drpei (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/fetched/ title=Fetched>Fetched (755)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/githubdaily/ title=GitHubDaily>GitHubDaily (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%B8%81%E9%A6%99%E5%9B%AD/ title=丁香园>丁香园 (30)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%BA%BA%E7%89%A9/ title=人物>人物 (15)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%8D%97%E6%96%B9%E5%91%A8%E6%9C%AB/ title=南方周末>南方周末 (11)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E4%BC%97%E8%BD%AF%E4%BB%B6/ title=小众软件>小众软件 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E5%A4%A7%E5%A4%AB%E6%BC%AB%E7%94%BB/ title=小大夫漫画>小大夫漫画 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%91%E6%95%B0%E6%B4%BE/ title=少数派>少数派 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%BE%AA%E5%9B%A0%E7%BC%89%E8%8D%AF/ title=循因缉药>循因缉药 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%96%B0%E4%B9%A1%E5%9C%9F/ title=新乡土>新乡土 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%98%9F%E7%90%83%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA/ title=星球商业评论>星球商业评论 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%88%E5%85%89%E5%8D%9A%E5%AE%A2/ title=月光博客>月光博客 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%AA%E9%97%BBcode/ title=未闻Code>未闻Code (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%A7%BD%E8%BE%B9%E5%BE%80%E4%BA%8B/ title=槽边往事>槽边往事 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%AF%8F%E6%97%A5%E4%BA%BA%E7%89%A9/ title=每日人物>每日人物 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AA%E6%BD%AE%E5%B7%A5%E4%BD%9C%E5%AE%A4/ title=浪潮工作室>浪潮工作室 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AE%E4%B9%8B%E9%9D%99/ title=浮之静>浮之静 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%81%BC%E8%A7%81/ title=灼见>灼见 (8)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%86%8A%E8%A8%80%E7%86%8A%E8%AF%AD/ title=熊言熊语>熊言熊语 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E6%8A%80%E8%83%BD%E6%A0%91/ title=生信技能树>生信技能树 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E8%8F%9C%E9%B8%9F%E5%9B%A2/ title=生信菜鸟团>生信菜鸟团 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%9F%A5%E8%AF%86%E5%88%86%E5%AD%90/ title=知识分子>知识分子 (14)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%BD%91%E6%98%93%E6%95%B0%E8%AF%BB/ title=网易数读>网易数读 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E6%96%B0/ title=财新>财新 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E7%BB%8F%E4%B8%89%E5%88%86%E9%92%9F/ title=财经三分钟>财经三分钟 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B5%9B%E5%85%88%E7%94%9F/ title=赛先生>赛先生 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E9%83%91%E5%B7%9E%E6%A5%BC%E5%B8%82/ title=郑州楼市>郑州楼市 (32)</a></div><a href=../../../tags/></a></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">Social</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Facebook rel="noopener noreferrer" href=https://facebook.com/username target=_blank><svg class="widget-social__link-icon icon icon-facebook" width="24" height="24" viewBox="0 0 352 352"><path d="m0 32v288c0 17.5 14.5 32 32 32h288c17.5.0 32-14.5 32-32V32c0-17.5-14.5-32-32-32H32C14.5.0.0 14.5.0 32zm320 0v288h-83V212h41.5l6-48H237v-31c0-14 3.5-23.5 23.5-23.5h26V66c-4.4-.6-19.8-1.5-37.5-1.5-36.9.0-62 22.2-62 63.5v36h-42v48h42v108H32V32z"/></svg>
<span>Facebook</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/username target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3C20 26 16.1 39.6 16.1 54c0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1C34.9 299 76.3 312 120.8 312c144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg>
<span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Instagram rel="noopener noreferrer" href=https://www.instagram.com/username target=_blank><svg class="widget-social__link-icon icon icon-instagram" width="24" height="24" viewBox="0 0 256 256"><circle cx="193" cy="59" r="15"/><path fill-rule="evenodd" d="M101 0h54c41 0 58.4 3.9 74.5 17C256.2 37.5 256 74.8 256 97.7v60c0 26.7.0 60.4-26.5 81.4-16 13.4-33.5 16.9-74.5 16.9h-54c-41 0-57.5-3.5-74.5-16.9C1 218.9.5 186.3.1 160.5L0 155V97.7c0-23-.2-60.2 26.5-80.7C45 2 60 0 101 0zm4.9 23h44.3c45.8.0 58.3 3.5 70.3 17.5 11.8 13.2 12 30.1 12.5 62.9V156c.2 20.8.3 45.8-12.5 59.5-12 14-24.5 17.5-70.3 17.5h-44.3c-45.9.0-57.3-3.5-70.4-17.5-12.2-13-12.3-36.5-12.4-56.7v-55.6c.4-32.6.7-49.6 12.4-62.7C48 26.5 60 23 105.9 23zm19.6 144.5a42 42 0 100-84 42 42 0 000 84zm0 22.5a64.5 64.5.0 100-129 64.5 64.5.0 000 129z"/></svg>
<span>Instagram</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 文字轨迹.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=../../../js/menu.js></script><script src=../../../js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>