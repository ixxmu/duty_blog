<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 - 文字轨迹</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://ixxmu.github.io/posts/2025-02/%E6%98%BE%E5%AD%98%E7%8B%82%E9%99%8D80__unsloth%E9%BB%91%E7%A7%91%E6%8A%80%E4%BC%98%E5%8C%96grpo%E6%B5%81%E7%A8%8B_%E8%AE%A9%E4%BA%BA%E4%BA%BA%E9%83%BD%E8%83%BD%E8%AE%AD%E8%87%AA%E5%B7%B1%E7%9A%84deepseek_r1/"><meta property="og:site_name" content="文字轨迹"><meta property="og:title" content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1"><meta property="og:description" content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 by 歸藏的AI工具箱 我们知道 Deepseek R1 核心的贡献是揭示了一个“aha”时刻，在 R1-Zero 中通过使用 GRPO （Group Relative Policy Optimization）在没有人类反馈的情况下自主学会了分配更多的思考时间。　开源社区也在其他模型上复现了类似的表现，不过成本很高，比如为Qwen2."><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2025-02-07T14:32:57+00:00"><meta property="article:modified_time" content="2025-02-07T14:32:57+00:00"><meta property="article:tag" content="Fetched"><meta property="article:tag" content="歸藏的AI工具箱"><meta itemprop=name content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1"><meta itemprop=description content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 by 歸藏的AI工具箱 我们知道 Deepseek R1 核心的贡献是揭示了一个“aha”时刻，在 R1-Zero 中通过使用 GRPO （Group Relative Policy Optimization）在没有人类反馈的情况下自主学会了分配更多的思考时间。　开源社区也在其他模型上复现了类似的表现，不过成本很高，比如为Qwen2."><meta itemprop=datePublished content="2025-02-07T14:32:57+00:00"><meta itemprop=dateModified content="2025-02-07T14:32:57+00:00"><meta itemprop=wordCount content="272"><meta itemprop=keywords content="Fetched,歸藏的AI工具箱"><meta name=twitter:card content="summary"><meta name=twitter:title content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1"><meta name=twitter:description content="显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 by 歸藏的AI工具箱 我们知道 Deepseek R1 核心的贡献是揭示了一个“aha”时刻，在 R1-Zero 中通过使用 GRPO （Group Relative Policy Optimization）在没有人类反馈的情况下自主学会了分配更多的思考时间。　开源社区也在其他模型上复现了类似的表现，不过成本很高，比如为Qwen2."><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../css/style.css><link rel=stylesheet href=../../../css/custom.css><link rel="shortcut icon" href=../../../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../ title=文字轨迹 rel=home><div class="logo__item logo__text"><div class=logo__title>文字轨迹</div><div class=logo__tagline>故事流淌过的地方</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../posts/><span class=menu__text>文章</span></a></li><li class=menu__item><a class=menu__link href=../../../tags/><span class=menu__text>标签</span></a></li><li class=menu__item><a class=menu__link href=../../../about/><span class=menu__text>关于</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><meta name=referrer content="never"><h1 class=post__title>显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2025-02-07T14:32:57Z>2025-02-07</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../categories/duty/ rel=category>Duty</a></span></div><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 16 16"><path d="M8 1c2 0 3.5 2 3.5 4.5S10 9 10 9c3 1 4 2 4 6H2c0-4 1-5 4-6 0 0-1.5-1-1.5-3.5S6 1 8 1"/></svg><span class=meta__text>Bloger</span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#显存狂降80unsloth黑科技优化grpo流程让人人都能训自己的deepseek-r1-by-歸藏的ai工具箱>显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 by 歸藏的AI工具箱</a></li></ul></nav></div></div><div class="content post__content clearfix"><h2 id=显存狂降80unsloth黑科技优化grpo流程让人人都能训自己的deepseek-r1-by-歸藏的ai工具箱>显存狂降80%！Unsloth黑科技优化GRPO流程，让人人都能训自己的Deepseek R1 by 歸藏的AI工具箱</h2><div><p><span>我们知道 Deepseek R1 核心的贡献是揭示了一个“aha”时刻，在 R1-Zero 中通过使用 GRPO （Group Relative Policy Optimization）在没有人类反馈的情况下自主学会了分配更多的思考时间。　</span></p><p><span>开源社区也在其他模型上复现了类似的表现，不过成本很高，比如为Qwen2.5（1.5B）实现推理也需要 160G 显存，根本不是个人可以承受的。　</span></p><p><span>但是今天 Unsloth AI 优化了优化了整个 GRPO 流程，让这个流程的显存占用节省了 80% ，<span>极限情况下你甚至可以用 8G 显卡搞定整个过程训练自己的推理模型</span>。　</span></p><p><span>注意不是对 R1 蒸馏模型微调，而是将标准模型转化为完整的推理模型！　</span></p><p><span><span>核心要点：</span>　</span></p><ul><li><p><span>凭借 15GB 的显存，Unsloth 能够将任何参数高达 150 亿的模型，如 Llama 3.1（8B）、Phi-4（14B）、Mistral（7B）或 Qwen2.5（7B），转化为推理模型。极限情况下只需要 7G 显存。</span></p></li><li><p><span>此前，GRPO 仅支持全量微调，Unsloth AI 使其能够与 QLoRA 和 LoRA 协同工作</span></p></li></ul><p><br></p><p><span>他们还提供了Colab笔记本，直接运行就行，这个可以直接将 Llama 8B 变成推理模型：<span><span>https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb</span>　</span></span></p><p>　</p><h2>GRPO + “aha”时刻</h2><p>Deepseek 的研究人员在用纯强化学习（RL）训练 R1-Zero 时观察到了一个“顿悟时刻”。该模型在没有人类指导或预设指令的情况下，通过重新评估其初始方法，学会了延长其思考时间。　</p><p>在一个测试示例中，他们仅使用 GRPO 对 Phi-4 进行了 100 步的训练，结果已显而易见。未采用 GRPO 的模型不具备思维标记，而经过 GRPO 训练的模型不仅拥有该标记，还给出了正确答案。　</p><section><img data-imgfileid=100003127 data-ratio=0.47848898216159497 data-src="https://mmbiz.qpic.cn/mmbiz_png/fbRX0iaT8EgcCjmXz7BIGVSw7OrYpbrWmicqxzj0JutbiaGnw9hBQQWVRsJibDia1JeF48IibefeXOxqLSfZAlqEOraA/640?wx_fmt=png&amp;from=appmsg" data-type=png data-w=3812 src="https://mmbiz.qpic.cn/mmbiz_png/fbRX0iaT8EgcCjmXz7BIGVSw7OrYpbrWmicqxzj0JutbiaGnw9hBQQWVRsJibDia1JeF48IibefeXOxqLSfZAlqEOraA/640?wx_fmt=png&amp;from=appmsg"></section><p>这种魔法可以通过 GRPO 重现，这是一种无需依赖价值函数即可高效优化响应的强化学习算法，与依赖价值函数的近端策略优化（PPO）不同。Unsloth AI 用 GRPO 训练模型，旨在使其自主发展出自我验证和搜索能力——创造一个小小的“顿悟时刻”。　</p><p><span>工作原理：</span>　</p><ul><li><p><span>该模型生成多组响应。</span></p></li><li><p><span>每个响应的评分基于正确性或由某种设定的奖励函数创建的其他指标，而非基于LLM奖励模型。</span></p></li><li><p><span>该组的平均分数被计算出来。</span></p></li><li><p><span>每个响应的得分与组内平均值进行比较。</span></p></li><li><p><span>该模型经过强化，以优先选择得分更高的响应。</span></p></li></ul><p>最初，人们需要收集大量数据来填充推理过程或思维链条。<span>但 GRPO（DeepSeek 使用的算法）或其他强化学习算法能够引导模型自动展现推理能力并生成推理轨迹。</span>相反，他们需要创建良好的奖励函数或验证器。　</p><p>例如，如果模型得出正确答案，就给它 1 分；如果某些单词拼写错误，就扣 0.1 分，以此类推！他们可以提供许多函数来奖励这一过程。　</p><p>　</p><h2>Unsloth 中的 GRPO 如何使用</h2><p>如果在本地使用 GRPO 与 Unsloth，请同时“pip install diffusers”，因为它是必需的依赖项。　</p><p>请至少等待 300 步，奖励才会实际增加，并请使用最新版本的 vLLM。请记住，在 Colab 上的示例仅训练了一小时，因此结果并不理想。为了获得良好的结果，需要至少训练 12 小时（这是 GRPO 的工作原理），但请记住，这并不是强制性的，可以随时停止。　</p><p>建议将 GRPO 应用于参数至少为 1.5B 的模型，以确保正确生成思维标记，因为较小的模型可能无法做到。如果使用的是基础模型，请确保拥有聊天模板。GRPO 的训练损失跟踪现已直接集成到 Unsloth 中，无需再依赖如 wandb 等外部工具。　</p><section><img data-imgfileid=100003126 data-ratio=0.4575775307197191 data-src="https://mmbiz.qpic.cn/mmbiz_png/fbRX0iaT8EgcCjmXz7BIGVSw7OrYpbrWmsNPZN3EMkSicy1rKIOe9KoqfBwVKghTqAdzIDVcGcAaf0gXq11cXEJg/640?wx_fmt=png&amp;from=appmsg" data-type=png data-w=1709 src="https://mmbiz.qpic.cn/mmbiz_png/fbRX0iaT8EgcCjmXz7BIGVSw7OrYpbrWmsNPZN3EMkSicy1rKIOe9KoqfBwVKghTqAdzIDVcGcAaf0gXq11cXEJg/640?wx_fmt=png&amp;from=appmsg"></section><h2><br></h2><h2>Unsloth x vLLM：吞吐量提升 20 倍，VRAM 节省 50%</h2><p>现在，你可以直接在微调堆栈中使用 vLLM，这大大提高了吞吐量，并允许您同时进行模型微调和推理！在 1 块 A100 40GB 显卡上，使用 Unsloth 对 Llama 3.2 3B Instruct 的动态 4 位量化，预计可达每秒 4000 个Token左右。而在 16GB 的 Tesla T4（免费 Colab GPU）上，您也能获得每秒 300 个Token的速度。　</p><p>他们还神奇地消除了同时加载 vLLM 和 Unsloth 时的双倍内存占用，使得 Llama 3.1 8B 节省了约 5GB，Llama 3.2 3B 节省了 3GB（灵感来源于 Boris）。Unsloth 最初能够在 1 块 48GB GPU 上微调 Llama 3.3 70B Instruct，其中 Llama 3.3 70B 权重占用 40GB 显存。如果不消除双倍内存占用，同时加载 Unsloth 和 vLLM 时将需要>=80GB 的显存。　</p><p>但有了 Unsloth，你仍能在不到 48GB 的显存中微调并享受快速推理的优势！要使用快速推理，首先安装 vllm，并通过 fast_inference 实例化 Unsloth：　</p><section><pre><code>pip install unsloth vllm<br><span>from</span> unsloth import FastLanguageModel<br>model, tokenizer = FastLanguageModel.from_pretrained(<br>    model_name = "unsloth/Llama-3.2-3B-Instruct",<br>    fast_inference = <span>True</span>,<br>)<br>model.fast_generate(["Hello!"])</code></pre></section><h2><br></h2><h2>Unsloth 在 vLLM 中的发现</h2><ul><li><p><span>vLLM 现在可以加载 Unsloth 动态 4 位量化模型。正如他们展示的 1.58 位动态 R1 GGUF 一样，动态地将某些层量化为 4 位，而其他层保持 16 位，可以在保持模型小巧的同时显著提升准确性。</span></p></li><li><p><span>他们自动选择多个参数以考虑 RAM、VRAM 效率和最大吞吐量（如分块预填充Token数、最大序列数等）。他们在 vLLM 中默认启用-O3 优化并开启前缀缓存。他们发现，在旧 GPU 上使用 Flashinfer 实际上会慢 10%。FP8 KV 缓存会使速度降低 10%，但吞吐量潜力翻倍。</span></p></li><li><p><span>他们通过解析状态字典而非从磁盘加载的方式，在 vLLM 中实现了 LoRA 的加载——这可以使您的 GRPO 训练速度提升 1.5 倍。当前一个活跃的研究领域是探索如何在 vLLM 中直接编辑 LoRA 适配器（具体方法尚不明确）。若能实现，将大幅提升速度，因为目前他们正在进行不必要的 GPU 数据传输。</span></p></li><li><p><span>vLLM 在批处理生成时会出现奇怪的 VRAM 随机峰值。他们添加了一个批处理生成函数以减少内存峰值。</span></p></li></ul><p>　</p><p><span>整理和分析不易，觉得有帮助的话可以点个赞或者再看，感谢🙏</span>　</p><p>　</p><p><span><span>来源：https://unsloth.ai/blog/r1-reasoning</span>　</span></p><p><br></p><p><mp-style-type data-value=3></mp-style-type></p></div><hr><a href=https://mp.weixin.qq.com/s/PeanD1CgSvF8clcP8gXyMg ,target=_blank rel="noopener noreferrer">原文链接</a></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=../../../tags/fetched/ rel=tag>fetched</a></li><li class=tags__item><a class="tags__link btn" href=../../../tags/%E6%AD%B8%E8%97%8F%E7%9A%84ai%E5%B7%A5%E5%85%B7%E7%AE%B1/ rel=tag>歸藏的AI工具箱</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><div class=authorbox__header><span class=authorbox__name>About Bloger</span></div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=../../../posts/2025-02/%E6%9D%9C%E7%90%AA%E5%B3%B0_%E6%A2%81%E6%9C%9D%E4%BC%9F%E6%97%B6%E9%9A%9427%E5%B9%B4%E5%86%8D%E5%90%88%E4%BD%9C_%E9%BB%91%E5%B8%AE%E6%96%B0%E7%89%872027%E5%B9%B4%E4%B8%8A%E6%98%A0/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>杜琪峰、梁朝伟时隔27年再合作 黑帮新片2027年上映</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=../../../posts/2025-02/%E5%8D%8E%E7%9B%9B%E9%A1%BF%E5%86%85%E5%B9%95_%E9%A9%AC%E6%96%AF%E5%85%8B%E6%9E%81%E5%85%B6%E5%8E%8C%E6%81%B6%E7%9A%84%E5%A5%A5%E5%B0%94%E7%89%B9%E6%9B%BC_%E5%A6%82%E4%BD%95%E8%B5%A2%E5%BE%97%E7%89%B9%E6%9C%97%E6%99%AE%E6%94%AF%E6%8C%81/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>华盛顿内幕：马斯克极其厌恶的奥尔特曼 如何赢得特朗普支持</p></a></div></nav><section class=comments><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kkitown.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><input class=widget-search__field type=search placeholder=Search… name=q aria-label=Search…>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://ixxmu.github.io/></form></div><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E9%97%B2%E9%B1%BC%E4%B8%8A%E9%82%A3%E4%BA%9B%E9%80%86%E5%A4%A9%E7%9A%84%E6%B5%8B%E5%BA%8F%E4%BB%AA/>闲鱼上那些逆天的测序仪</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E8%AF%B4%E8%B5%B7%E8%BE%9B%E8%8A%B7%E8%95%BE_%E6%88%91%E6%83%B3%E8%B5%B7%E6%97%A9%E5%B9%B4%E4%B8%80%E4%BA%9B%E5%93%81%E5%91%B3_%E7%8B%AC%E7%89%B9_%E7%9A%84%E6%81%90%E6%80%96%E7%89%87/>说起辛芷蕾，我想起早年一些品味“独特”的恐怖片</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%A4%9A%E6%AC%A1%E7%94%9F%E5%AD%90%E5%90%8E_28%E5%B2%81%E5%86%9C%E6%9D%91%E6%99%BA%E9%9A%9C%E5%A5%B3%E5%AD%A9%E6%82%84%E7%84%B6%E7%A6%BB%E4%B8%96/>多次生子后，28岁农村智障女孩悄然离世</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/openai%E7%BD%95%E8%A7%81%E5%8F%91%E8%AE%BA%E6%96%87_%E6%88%91%E4%BB%AC%E6%89%BE%E5%88%B0%E4%BA%86ai%E5%B9%BB%E8%A7%89%E7%9A%84%E7%BD%AA%E9%AD%81%E7%A5%B8%E9%A6%96/>OpenAI罕见发论文：我们找到了AI幻觉的罪魁祸首</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-09/%E5%8D%97%E4%BA%AC%E5%8D%96%E6%B7%AB%E5%A4%B4%E7%9B%AE1_34%E4%BA%BF%E6%B8%AF%E5%85%83%E8%A2%AB%E7%91%9E%E9%93%B6%E5%8E%9F%E5%89%AF%E6%80%BB%E7%9B%91%E7%A7%81%E5%90%9E/>南京卖淫头目1.34亿港元被瑞银原副总监私吞</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../categories/duty/>Duty</a></li><li class=widget__item><a class=widget__link href=../../../categories/duty2/>Duty2</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>Tags</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=../../../tags/cnbeta/ title=Cnbeta>Cnbeta (148)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/datawhale/ title=Datawhale>Datawhale (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/drpei/ title=Drpei>Drpei (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/fetched/ title=Fetched>Fetched (755)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/githubdaily/ title=GitHubDaily>GitHubDaily (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%B8%81%E9%A6%99%E5%9B%AD/ title=丁香园>丁香园 (30)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%BA%BA%E7%89%A9/ title=人物>人物 (15)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%8D%97%E6%96%B9%E5%91%A8%E6%9C%AB/ title=南方周末>南方周末 (11)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E4%BC%97%E8%BD%AF%E4%BB%B6/ title=小众软件>小众软件 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E5%A4%A7%E5%A4%AB%E6%BC%AB%E7%94%BB/ title=小大夫漫画>小大夫漫画 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%91%E6%95%B0%E6%B4%BE/ title=少数派>少数派 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%BE%AA%E5%9B%A0%E7%BC%89%E8%8D%AF/ title=循因缉药>循因缉药 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%96%B0%E4%B9%A1%E5%9C%9F/ title=新乡土>新乡土 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%98%9F%E7%90%83%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA/ title=星球商业评论>星球商业评论 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%88%E5%85%89%E5%8D%9A%E5%AE%A2/ title=月光博客>月光博客 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%AA%E9%97%BBcode/ title=未闻Code>未闻Code (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%A7%BD%E8%BE%B9%E5%BE%80%E4%BA%8B/ title=槽边往事>槽边往事 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%AF%8F%E6%97%A5%E4%BA%BA%E7%89%A9/ title=每日人物>每日人物 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AA%E6%BD%AE%E5%B7%A5%E4%BD%9C%E5%AE%A4/ title=浪潮工作室>浪潮工作室 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AE%E4%B9%8B%E9%9D%99/ title=浮之静>浮之静 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%81%BC%E8%A7%81/ title=灼见>灼见 (8)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%86%8A%E8%A8%80%E7%86%8A%E8%AF%AD/ title=熊言熊语>熊言熊语 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E6%8A%80%E8%83%BD%E6%A0%91/ title=生信技能树>生信技能树 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E8%8F%9C%E9%B8%9F%E5%9B%A2/ title=生信菜鸟团>生信菜鸟团 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%9F%A5%E8%AF%86%E5%88%86%E5%AD%90/ title=知识分子>知识分子 (14)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%BD%91%E6%98%93%E6%95%B0%E8%AF%BB/ title=网易数读>网易数读 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E6%96%B0/ title=财新>财新 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E7%BB%8F%E4%B8%89%E5%88%86%E9%92%9F/ title=财经三分钟>财经三分钟 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B5%9B%E5%85%88%E7%94%9F/ title=赛先生>赛先生 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E9%83%91%E5%B7%9E%E6%A5%BC%E5%B8%82/ title=郑州楼市>郑州楼市 (32)</a></div><a href=../../../tags/></a></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">Social</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Facebook rel="noopener noreferrer" href=https://facebook.com/username target=_blank><svg class="widget-social__link-icon icon icon-facebook" width="24" height="24" viewBox="0 0 352 352"><path d="m0 32v288c0 17.5 14.5 32 32 32h288c17.5.0 32-14.5 32-32V32c0-17.5-14.5-32-32-32H32C14.5.0.0 14.5.0 32zm320 0v288h-83V212h41.5l6-48H237v-31c0-14 3.5-23.5 23.5-23.5h26V66c-4.4-.6-19.8-1.5-37.5-1.5-36.9.0-62 22.2-62 63.5v36h-42v48h42v108H32V32z"/></svg>
<span>Facebook</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/username target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3C20 26 16.1 39.6 16.1 54c0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1C34.9 299 76.3 312 120.8 312c144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg>
<span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Instagram rel="noopener noreferrer" href=https://www.instagram.com/username target=_blank><svg class="widget-social__link-icon icon icon-instagram" width="24" height="24" viewBox="0 0 256 256"><circle cx="193" cy="59" r="15"/><path fill-rule="evenodd" d="M101 0h54c41 0 58.4 3.9 74.5 17C256.2 37.5 256 74.8 256 97.7v60c0 26.7.0 60.4-26.5 81.4-16 13.4-33.5 16.9-74.5 16.9h-54c-41 0-57.5-3.5-74.5-16.9C1 218.9.5 186.3.1 160.5L0 155V97.7c0-23-.2-60.2 26.5-80.7C45 2 60 0 101 0zm4.9 23h44.3c45.8.0 58.3 3.5 70.3 17.5 11.8 13.2 12 30.1 12.5 62.9V156c.2 20.8.3 45.8-12.5 59.5-12 14-24.5 17.5-70.3 17.5h-44.3c-45.9.0-57.3-3.5-70.4-17.5-12.2-13-12.3-36.5-12.4-56.7v-55.6c.4-32.6.7-49.6 12.4-62.7C48 26.5 60 23 105.9 23zm19.6 144.5a42 42 0 100-84 42 42 0 000 84zm0 22.5a64.5 64.5.0 100-129 64.5 64.5.0 000 129z"/></svg>
<span>Instagram</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 文字轨迹.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=../../../js/menu.js></script><script src=../../../js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>