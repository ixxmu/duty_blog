<!doctype html><html class=no-js lang=en><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>微信版大语言模型：论文、API接口、在线试玩网站......一应俱全 - 文字轨迹</title>
<script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><meta property="og:url" content="https://ixxmu.github.io/posts/others/%E5%BE%AE%E4%BF%A1%E7%89%88%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B_%E8%AE%BA%E6%96%87_api%E6%8E%A5%E5%8F%A3_%E5%9C%A8%E7%BA%BF%E8%AF%95%E7%8E%A9%E7%BD%91%E7%AB%99______%E4%B8%80%E5%BA%94%E4%BF%B1%E5%85%A8/"><meta property="og:site_name" content="文字轨迹"><meta property="og:title" content="微信版大语言模型：论文、API接口、在线试玩网站......一应俱全"><meta property="og:description" content="微信版大语言模型：论文、API接口、在线试玩网站……一应俱全 by cnbeta 大规模语言模型， 微信版，来了！并且甫一登场，就没藏着掖着：论文、API接口、在线试玩网站……一条龙全都齐备。续写文本、阅读理解等常规任务就不说了，这个名叫 WeLM的AI，竟然直接让我和李白跨时空聊起了杜甫："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-10-13T14:18:15+00:00"><meta property="article:modified_time" content="2022-10-13T14:18:15+00:00"><meta property="article:tag" content="Fetched"><meta property="article:tag" content="Cnbeta"><meta itemprop=name content="微信版大语言模型：论文、API接口、在线试玩网站......一应俱全"><meta itemprop=description content="微信版大语言模型：论文、API接口、在线试玩网站……一应俱全 by cnbeta 大规模语言模型， 微信版，来了！并且甫一登场，就没藏着掖着：论文、API接口、在线试玩网站……一条龙全都齐备。续写文本、阅读理解等常规任务就不说了，这个名叫 WeLM的AI，竟然直接让我和李白跨时空聊起了杜甫："><meta itemprop=datePublished content="2022-10-13T14:18:15+00:00"><meta itemprop=dateModified content="2022-10-13T14:18:15+00:00"><meta itemprop=wordCount content="114"><meta itemprop=keywords content="Fetched,Cnbeta"><meta name=twitter:card content="summary"><meta name=twitter:title content="微信版大语言模型：论文、API接口、在线试玩网站......一应俱全"><meta name=twitter:description content="微信版大语言模型：论文、API接口、在线试玩网站……一应俱全 by cnbeta 大规模语言模型， 微信版，来了！并且甫一登场，就没藏着掖着：论文、API接口、在线试玩网站……一条龙全都齐备。续写文本、阅读理解等常规任务就不说了，这个名叫 WeLM的AI，竟然直接让我和李白跨时空聊起了杜甫："><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../css/style.css><link rel=stylesheet href=../../../css/custom.css><link rel="shortcut icon" href=../../../favicon.ico></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../ title=文字轨迹 rel=home><div class="logo__item logo__text"><div class=logo__title>文字轨迹</div><div class=logo__tagline>故事流淌过的地方</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../posts/><span class=menu__text>文章</span></a></li><li class=menu__item><a class=menu__link href=../../../tags/><span class=menu__text>标签</span></a></li><li class=menu__item><a class=menu__link href=../../../about/><span class=menu__text>关于</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><meta name=referrer content="never"><h1 class=post__title>微信版大语言模型：论文、API接口、在线试玩网站......一应俱全</h1><div class="post__meta meta"><div class="meta__item-datetime meta__item"><svg class="meta__icon icon icon-time" width="16" height="14" viewBox="0 0 30 28"><path d="M15 0a14 14 0 110 28 1 1 0 010-28m0 3a3 3 0 100 22 3 3 0 000-22m1 4h-2v8.4l6.8 4.4L22 18l-6-3.8z"/></svg><time class=meta__text datetime=2022-10-13T14:18:15Z>2022-10-13</time></div><div class="meta__item-categories meta__item"><svg class="meta__icon icon icon-category" width="16" height="16" viewBox="0 0 16 16"><path d="m7 2 1 2h8v11H0V2z"/></svg><span class=meta__text><a class=meta__link href=../../../categories/duty/ rel=category>Duty</a></span></div><div class="meta__item-author meta__item"><svg class="meta__icon icon icon-author" width="16" height="16" viewBox="0 0 16 16"><path d="M8 1c2 0 3.5 2 3.5 4.5S10 9 10 9c3 1 4 2 4 6H2c0-4 1-5 4-6 0 0-1.5-1-1.5-3.5S6 1 8 1"/></svg><span class=meta__text>Bloger</span></div></div></header><div class="post__toc toc"><div class=toc__title>Page content</div><div class=toc__menu><nav id=TableOfContents><ul><li><a href=#微信版大语言模型论文api接口在线试玩网站一应俱全-by-cnbeta>微信版大语言模型：论文、API接口、在线试玩网站&mldr;&mldr;一应俱全 by cnbeta</a></li></ul></nav></div></div><div class="content post__content clearfix"><h2 id=微信版大语言模型论文api接口在线试玩网站一应俱全-by-cnbeta>微信版大语言模型：论文、API接口、在线试玩网站&mldr;&mldr;一应俱全 by cnbeta</h2><div style=margin-top:10px class=content id=artibody><p><strong>大规模语言模型， 微信版，来了！并且甫一登场，就没藏着掖着：论文、API接口、在线试玩网站……一条龙全都齐备。</strong>续写文本、阅读理解等常规任务就不说了，这个名叫 WeLM的AI，竟然直接让我和李白跨时空聊起了杜甫：</p><div class=article-global><p><strong>访问：</strong></p><p><a href="https://c.duomai.com/track.php?site_id=242986&amp;euid=&amp;t=https://www.microsoftstore.com.cn/" target=_blank><span style=color:#c00000>国行Surface Pro 9/Laptop 5和Surface Studio 2+新品已上架预售</span></a></p></div><p style=text-align:left>原标题：微信版大语言模型来了：跨时空对话李白、教你高情商说话，API在线试玩全都有</p><p style=text-align:left>鱼羊 梦晨 发自 凹非寺</p><blockquote style=text-align:left><p style=text-align:left>我：现在有一首关于你的歌，其中一句歌词是“要是能重来，我要选李白”，请问你自己有什么看法？</p><p style=text-align:left>李白：我要选杜甫。</p></blockquote><p style=text-align:left>我：现在有一首关于你的歌，其中一句歌词是“要是能重来，我要选李白”，请问你自己有什么看法？</p><p style=text-align:left>李白：我要选杜甫。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/47918867957df2a.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/47918867957df2a.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/47918867957df2a.png></a></p><p style=text-align:left>这还不算完，WeLM甚至还治好了我不会聊天的毛病，分分钟教会我如何高情商说话。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/a5dc42c9f4269bb.jpeg><img data-original=https://static.cnbetacdn.com/article/2022/1013/a5dc42c9f4269bb.jpeg src=https://static.cnbetacdn.com/thumb/article/2022/1013/a5dc42c9f4269bb.jpeg></a></p><p style=text-align:left>这么一个AI，参数量不算大，目前处于 <strong>百亿</strong>水平。</p><p style=text-align:left>但值得关注的是，实验结果显示，它在18个中文语言任务里， <strong>效果堪比参数量是其25倍的模型</strong>。</p><p style=text-align:left>是不是有点手痒想上手一试了？先奉上链接，咱们再仔细说说，这波微信是怎么做到的。</p><blockquote style=text-align:left><p style=text-align:left>体验链接：https://welm.weixin.qq.com/docs/playground/</p><p style=text-align:left>API接口：https://welm.weixin.qq.com/docs/api/</p><p style=text-align:left>论文地址：https://arxiv.org/abs/2209.10372</p></blockquote><p style=text-align:left>体验链接：https://welm.weixin.qq.com/docs/playground/</p><p style=text-align:left>API接口：https://welm.weixin.qq.com/docs/api/</p><p style=text-align:left>论文地址：https://arxiv.org/abs/2209.10372</p><p style=text-align:left>微信语言大模型WeLM，全名Well-Read Language Model，也就是 <strong>“学富五车的语言模型”</strong>。</p><p style=text-align:left>在翻译任务上，WeLM不光可以做到基本的，甚至 <strong>三语夹杂</strong>也难不倒它。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/a75747c80afd9a6.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/a75747c80afd9a6.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/a75747c80afd9a6.png></a></p><p style=text-align:left>在文本续写任务上， <strong>只需给出开头</strong>就能生成适应不同风格的文本。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/ea2144fce91e884.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/ea2144fce91e884.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/ea2144fce91e884.png></a></p><p style=text-align:left>这种多语言、多任务能力是怎么做到的？</p><p style=text-align:left>其实WeLM与著名的GPT-3是同类，都是自回归解码器结构，微信团队选择这种结构就是看中其 <strong>在海量数据中掌握无穷范式</strong>的能力。</p><p style=text-align:left>在具体实现方法上，WeLM还有两项特色。</p><p style=text-align:left>一是采用RoPE相对位置编码，与传统的固定位置编码相比能更好处理长文本，比如理解整篇文章甚至整本书。</p><p style=text-align:left>二是使用62k个token的SentencePiece并保留其中的空格和Tab，这样更有利于下游任务。</p><p style=text-align:left>使用这些方法，WeLM总共设计了从13亿到100亿参数的三个版本，可按需调用。</p><p style=text-align:left><strong>其中100亿参数的满血版WeLM在14项中文任务中整体表现超过同大小的模型，甚至在零样本任务上超过比它大25倍的模型。</strong></p><p style=text-align:left>这其中最大的秘诀就是精心准备的高质量训练数据上充分训练，也就是“学富五车”的含义所在。</p><p style=text-align:left>高质量训练数据包括从Common Crawl下载的近两年中文网页、大量书籍、新闻、论坛数据和学术论文。</p><p style=text-align:left>收集到的数据总量超过10TB，其中包含750G英文数据，中文中夹杂的英日韩语为了语义连贯也全部保留。</p><p style=text-align:left>不过这还不算完，需要经过清洗、去重等一系列步骤才能算得上是高质量数据。</p><p style=text-align:left>首先是去除噪声和脏数据，结合使用规则和模型检测后，超过87%的数据被过滤。</p><p style=text-align:left>再利用SimHash算法去重，进一步过滤掉40%的数据。</p><p style=text-align:left>接下来要去除一切和测评相关的数据，保证公平性，以 17-gram 为检测重复粒度再次过滤了0.15%的数据。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/c795ebaf3cc13ff.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/c795ebaf3cc13ff.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/c795ebaf3cc13ff.png></a></p><p style=text-align:left>一系列处理后留下的数据量为 <strong>262B tokens</strong>，最后再对这些数据进行不同比重的采样，使数据平滑分布在各个话题上。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/6aa01f89950d314.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/6aa01f89950d314.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/6aa01f89950d314.png></a></p><p style=text-align:left>对于预训练，团队认为当今多数大模型的训练都不够充分，WeLM 100亿参数版的训练量基本与1750亿的GPT-3相当 （300B tokens），在128张A100上训练用了大概24天时间。</p><p style=text-align:left>为了保证训练效率，WeLM在训练过程中还使用了完全可原地复现的形式，不管发生任何问题都能从最近的checkpoint恢复。</p><p style=text-align:left>自1750亿参数的GPT-3之后，语言模型规模越来越大，到今年Google的PaLM已经达到5400亿，中文大模型同样有这个趋势。</p><p style=text-align:left>可以看出微信团队选择了另一条路线，以高质量训练数据和高效训练做到 <strong>“四两拨千斤”</strong>的效果。</p><p style=text-align:left><strong>到这一步WeLM已经有了不错的表现，不过接下来这个步骤再次将其 零样本泛化能力提到新的高度 。</strong></p><p style=text-align:left>研究团队针对76个数据集各人工撰写10-20个Prompt，将原任务中的文本关系的标签和输入信息转化成流畅通顺的自然语言形式，更符合自回归语言模型的训练形式。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/8f5b9dac3099f27.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/8f5b9dac3099f27.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/8f5b9dac3099f27.png></a></p><p style=text-align:left>使用这些Prompt对模型微调后，相当于让模型学会了面对多样的Prompt该做什么。如果遇到相似Prompt形式的全新任务，也可以有更稳定的表现。</p><p style=text-align:left>实验证明，在全量数据上微调后的模型在新的NLP任务上具备更优秀的 <strong>零样本迁移能力</strong>，同时也使得微调变为一项 <strong>一劳永逸</strong>的工作。</p><p style=text-align:left><strong>最后，研究团队还测试了WeLM的三个额外能力。</strong></p><p style=text-align:left>通过提供示例，WeLM可以 <strong>对自己的决策作出解释</strong>，不过这种能力不太稳定，还需要进一步探索。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/2da02ef604b85d4.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/2da02ef604b85d4.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/2da02ef604b85d4.png></a></p><p style=text-align:left>通过简单提问，WeLM可以对结果进行 <strong>自我纠正和检查</strong>能力，为后续提高性能提供了可能方向。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/13fad6b68b5385d.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/13fad6b68b5385d.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/13fad6b68b5385d.png></a></p><p style=text-align:left>WeLM还表现出一定的 <strong>记忆能力</strong>，如果输入内容完美匹配前文，即使内容很长、出现频次很低，模型依然可以准确的生成剩下的部分。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/3000195981c1660.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/3000195981c1660.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/3000195981c1660.png></a></p><p style=text-align:left>最后再来总结一下，WeLM精通中文的同时掌握英日韩等多种外语、可以通过少样本或零样本学习执行全新任务，同时以合理尺寸做到与25倍参数量的模型相媲美使用成本较低，总之就是奔着 <strong>实用性</strong>和 <strong>大规模落地</strong>去的。</p><p style=text-align:left>同步开放在线体验与API，也是希望有想法的开发者能方便的用起来，让WeLM大模型真正实用的工具。</p><p style=text-align:left>WeLM怎么用</p><p style=text-align:left>具体来说，WeLM线上Demo目前释出的功能包括：对话-采访、阅读理解、翻译、改写、续写以及自由任务。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/5fed8c6d8204c15.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/5fed8c6d8204c15.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/5fed8c6d8204c15.png></a></p><p style=text-align:left>在正式开始跟WeLM玩耍之前，记得要先给模型扔一段简单的“范文”，也就是“prompt”。</p><p style=text-align:left>在线网站会给出一些默认的prompt，你也可以自行修改设计。需要遵循的设计原则是：</p><blockquote style=text-align:left><p style=text-align:left>第一，描述清楚；第二，例子具备代表性（多个例子更好）。</p></blockquote><p style=text-align:left>第一，描述清楚；第二，例子具备代表性（多个例子更好）。</p><p style=text-align:left>以文本分类任务为例，prompt应该长这样：</p><p style=text-align:left>其中的技巧包括，首先，把分类任务用 <strong>自然语言</strong>清晰地表达出来，在上面这个示例中，“微博”即为输入，“类别”即为输出。</p><p style=text-align:left>其次，在第一句的指令型描述中，需要把可能的分类结果都列出来。</p><p style=text-align:left>最后，如果效果不佳，可以尝试加入更多例子，让WeLM更清楚你到底想要做怎样的任务。</p><p style=text-align:left>另外，正如前文所说，WeLM拥有零样本学习能力。</p><p style=text-align:left>所以直接把它当作问答搜索引擎来用，也不是不行（手动狗头）。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/d89dd028a47e58a.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/d89dd028a47e58a.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/d89dd028a47e58a.png></a></p><p style=text-align:left>如果你还想得到更多样化的生成结果，token数量、temperature等参数均可调整。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/b8097a2a35238f1.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/b8097a2a35238f1.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/b8097a2a35238f1.png></a></p><p style=text-align:left>更重要的一点是，WeLM已 <strong>开放API接口</strong>。也就是说，如果身为开发者的你想在自己的App里用上这个大模型，填写调查问卷注册即可。</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/be2c23e50d2ed45.png><img data-original=https://static.cnbetacdn.com/article/2022/1013/be2c23e50d2ed45.png src=https://static.cnbetacdn.com/thumb/article/2022/1013/be2c23e50d2ed45.png></a></p><p style=text-align:left>One More Thing</p><p style=text-align:left>说起来，这样的大模型要是真的落地应用了，妈妈岂不是再也不用担心我因为不会聊天 而母胎solo？</p><p style=text-align:left>比如说……</p><p style=text-align:center><a target=_blank href=https://static.cnbetacdn.com/article/2022/1013/41c3771f271c4fc.jpeg><img data-original=https://static.cnbetacdn.com/article/2022/1013/41c3771f271c4fc.jpeg src=https://static.cnbetacdn.com/thumb/article/2022/1013/41c3771f271c4fc.jpeg></a></p><p style=text-align:left>你还有什么有趣的脑洞？大胆招呼起来~</p></div><hr><a href=https://m.cnbeta.com/wap/view/1326721.htm ,target=_blank rel="noopener noreferrer">原文链接</a></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M4 0h8s2 0 4 2l15 15s2 2 0 4L21 31s-2 2-4 0L2 16s-2-2-2-4V3s0-3 4-3m3 10a3 3 0 000-6 3 3 0 000 6"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=../../../tags/fetched/ rel=tag>fetched</a></li><li class=tags__item><a class="tags__link btn" href=../../../tags/cnbeta/ rel=tag>cnbeta</a></li></ul></div></footer></article></main><div class="authorbox clearfix"><div class=authorbox__header><span class=authorbox__name>About Bloger</span></div></div><nav class="pager flex"><div class="pager__item pager__item--prev"><a class=pager__link href=../../../posts/others/%E6%A4%B0%E6%A0%91%E7%94%A8%E5%A4%A7%E8%83%B8%E5%A5%B3%E4%B8%BB%E6%92%AD%E5%90%8E_%E8%88%86%E8%AE%BA%E5%8F%8D%E8%BD%AC%E4%BA%86_/ rel=prev><span class=pager__subtitle>«&#8201;Previous</span><p class=pager__title>椰树用大胸女主播后，舆论反转了！</p></a></div><div class="pager__item pager__item--next"><a class=pager__link href=../../../posts/others/%E8%BF%9C%E5%8F%A4%E6%9C%A8%E4%B9%83%E4%BC%8A%E4%B8%8E%E7%8E%B0%E4%BB%A3%E5%8C%BB%E5%AD%A6%E6%88%90%E5%83%8F%E7%9A%84%E5%91%BC%E5%BA%94_%E4%B8%8D%E6%AD%A2%E4%BA%8E%E8%89%BA%E6%9C%AF/ rel=next><span class=pager__subtitle>Next&#8201;»</span><p class=pager__title>远古木乃伊与现代医学成像的呼应｜不止于艺术</p></a></div></nav><section class=comments><div id=disqus_thread></div><script>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kkitown.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div><aside class=sidebar><div class="widget-search widget"><form class=widget-search__form role=search method=get action=https://google.com/search><input class=widget-search__field type=search placeholder=Search… name=q aria-label=Search…>
<input class=widget-search__submit type=submit value=Search>
<input type=hidden name=sitesearch value=https://ixxmu.github.io/></form></div><div class="widget-recent widget"><h4 class=widget__title>Recent Posts</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../posts/2025-12/gpt_5_2%E5%8F%91%E5%B8%83_%E7%9C%9F%E6%AD%A3%E7%9A%84%E7%89%9B%E9%A9%AC%E6%89%93%E5%B7%A5%E4%BA%BA%E4%B8%93%E5%B1%9Eai%E6%9D%A5%E4%BA%86_/>GPT-5.2发布，真正的牛马打工人专属AI来了。</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-12/google_scholar%E8%A2%AB%E7%8E%A9%E5%9D%8F_10%E7%AF%87_%E6%B0%B4%E6%96%87_%E5%88%B7%E5%87%BA600_%E5%BC%95%E7%94%A8_h_index%E8%BF%98%E8%83%BD%E4%BF%A1%E5%90%97_/>Google Scholar被玩坏：10篇“水文”刷出600+引用，H-index还能信吗？</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-12/%E5%90%8E%E6%B5%AA%E5%8D%B7%E6%AD%BB%E5%89%8D%E6%B5%AA__%E8%B0%B7%E6%AD%8C%E9%93%BE_%E5%B9%B4%E5%86%85%E6%B6%A8%E5%B9%85%E5%B7%B2%E5%BF%AB%E6%8E%A5%E8%BF%91_openai%E9%93%BE_%E7%9A%84%E4%B8%A4%E5%80%8D/>后浪卷死前浪？“谷歌链”年内涨幅已快接近“OpenAI链”的两倍</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-12/%E6%88%AA%E8%83%A1%E5%A5%88%E9%A3%9E_%E6%B4%BE%E6%8B%89%E8%92%99%E5%90%91%E5%8D%8E%E7%BA%B3%E5%85%84%E5%BC%9F%E5%8F%91%E8%B5%B7%E6%95%8C%E6%84%8F%E6%94%B6%E8%B4%AD%E8%A6%81%E7%BA%A6/>截胡奈飞？派拉蒙向华纳兄弟发起敌意收购要约</a></li><li class=widget__item><a class=widget__link href=../../../posts/2025-12/%E5%8F%B0%E7%A7%AF%E7%94%B5%E4%B9%B0%E8%B5%B0euv%E5%85%89%E5%88%BB%E6%9C%BA10%E5%B9%B4%E6%9D%A5%E4%B8%80%E5%8D%8A%E4%BA%A7%E9%87%8F/>台积电买走EUV光刻机10年来一半产量</a></li></ul></div></div><div class="widget-categories widget"><h4 class=widget__title>Categories</h4><div class=widget__content><ul class=widget__list><li class=widget__item><a class=widget__link href=../../../categories/duty/>Duty</a></li><li class=widget__item><a class=widget__link href=../../../categories/duty2/>Duty2</a></li></ul></div></div><div class="widget-taglist widget"><h4 class=widget__title>Tags</h4><div class=widget__content><a class="widget-taglist__link widget__link btn" href=../../../tags/cnbeta/ title=Cnbeta>Cnbeta (175)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/datawhale/ title=Datawhale>Datawhale (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/drpei/ title=Drpei>Drpei (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/fetched/ title=Fetched>Fetched (821)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/githubdaily/ title=GitHubDaily>GitHubDaily (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%B8%81%E9%A6%99%E5%9B%AD/ title=丁香园>丁香园 (30)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E4%BA%BA%E7%89%A9/ title=人物>人物 (16)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%8D%97%E6%96%B9%E5%91%A8%E6%9C%AB/ title=南方周末>南方周末 (12)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E4%BC%97%E8%BD%AF%E4%BB%B6/ title=小众软件>小众软件 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%8F%E5%A4%A7%E5%A4%AB%E6%BC%AB%E7%94%BB/ title=小大夫漫画>小大夫漫画 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%B0%91%E6%95%B0%E6%B4%BE/ title=少数派>少数派 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E5%BE%AA%E5%9B%A0%E7%BC%89%E8%8D%AF/ title=循因缉药>循因缉药 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%96%B0%E4%B9%A1%E5%9C%9F/ title=新乡土>新乡土 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%98%9F%E7%90%83%E5%95%86%E4%B8%9A%E8%AF%84%E8%AE%BA/ title=星球商业评论>星球商业评论 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%88%E5%85%89%E5%8D%9A%E5%AE%A2/ title=月光博客>月光博客 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%9C%AA%E9%97%BBcode/ title=未闻Code>未闻Code (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%A7%BD%E8%BE%B9%E5%BE%80%E4%BA%8B/ title=槽边往事>槽边往事 (9)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%AF%8F%E6%97%A5%E4%BA%BA%E7%89%A9/ title=每日人物>每日人物 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AA%E6%BD%AE%E5%B7%A5%E4%BD%9C%E5%AE%A4/ title=浪潮工作室>浪潮工作室 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E6%B5%AE%E4%B9%8B%E9%9D%99/ title=浮之静>浮之静 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%81%BC%E8%A7%81/ title=灼见>灼见 (8)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%86%8A%E8%A8%80%E7%86%8A%E8%AF%AD/ title=熊言熊语>熊言熊语 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E6%8A%80%E8%83%BD%E6%A0%91/ title=生信技能树>生信技能树 (10)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%94%9F%E4%BF%A1%E8%8F%9C%E9%B8%9F%E5%9B%A2/ title=生信菜鸟团>生信菜鸟团 (6)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%9F%A5%E8%AF%86%E5%88%86%E5%AD%90/ title=知识分子>知识分子 (14)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E7%BD%91%E6%98%93%E6%95%B0%E8%AF%BB/ title=网易数读>网易数读 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E6%96%B0/ title=财新>财新 (8)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B4%A2%E7%BB%8F%E4%B8%89%E5%88%86%E9%92%9F/ title=财经三分钟>财经三分钟 (7)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E8%B5%9B%E5%85%88%E7%94%9F/ title=赛先生>赛先生 (5)</a>
<a class="widget-taglist__link widget__link btn" href=../../../tags/%E9%83%91%E5%B7%9E%E6%A5%BC%E5%B8%82/ title=郑州楼市>郑州楼市 (33)</a></div><a href=../../../tags/></a></div><div class="widget-social widget"><h4 class="widget-social__title widget__title">Social</h4><div class="widget-social__content widget__content"><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Facebook rel="noopener noreferrer" href=https://facebook.com/username target=_blank><svg class="widget-social__link-icon icon icon-facebook" width="24" height="24" viewBox="0 0 352 352"><path d="m0 32v288c0 17.5 14.5 32 32 32h288c17.5.0 32-14.5 32-32V32c0-17.5-14.5-32-32-32H32C14.5.0.0 14.5.0 32zm320 0v288h-83V212h41.5l6-48H237v-31c0-14 3.5-23.5 23.5-23.5h26V66c-4.4-.6-19.8-1.5-37.5-1.5-36.9.0-62 22.2-62 63.5v36h-42v48h42v108H32V32z"/></svg>
<span>Facebook</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Twitter rel="noopener noreferrer" href=https://twitter.com/username target=_blank><svg class="widget-social__link-icon icon icon-twitter" width="24" height="24" viewBox="0 0 384 312"><path d="m384 36.9c-14.1 6.3-29.3 10.5-45.2 12.4 16.3-9.7 28.8-25.2 34.6-43.6-15.2 9-32.1 15.6-50 19.1-14.4-15.2-34.9-24.8-57.5-24.8-43.5.0-78.8 35.3-78.8 78.8.0 6.2.7 12.2 2 17.9-65.5-3.3-123.5-34.6-162.4-82.3C20 26 16.1 39.6 16.1 54c0 27.3 13.9 51.4 35 65.6-12.9-.4-25.1-4-35.7-9.9v1c0 38.2 27.2 70 63.2 77.2-6.6 1.8-13.6 2.8-20.8 2.8-5.1.0-10-.5-14.8-1.4 10 31.3 39.1 54.1 73.6 54.7-27 21.1-60.9 33.7-97.8 33.7-6.4.0-12.6-.4-18.8-1.1C34.9 299 76.3 312 120.8 312c144.9.0 224.1-120 224.1-224.1.0-3.4-.1-6.8-.2-10.2 15.4-11.1 28.7-25 39.3-40.8z"/></svg>
<span>Twitter</span></a></div><div class="widget-social__item widget__item"><a class="widget-social__link widget__link btn" title=Instagram rel="noopener noreferrer" href=https://www.instagram.com/username target=_blank><svg class="widget-social__link-icon icon icon-instagram" width="24" height="24" viewBox="0 0 256 256"><circle cx="193" cy="59" r="15"/><path fill-rule="evenodd" d="M101 0h54c41 0 58.4 3.9 74.5 17C256.2 37.5 256 74.8 256 97.7v60c0 26.7.0 60.4-26.5 81.4-16 13.4-33.5 16.9-74.5 16.9h-54c-41 0-57.5-3.5-74.5-16.9C1 218.9.5 186.3.1 160.5L0 155V97.7c0-23-.2-60.2 26.5-80.7C45 2 60 0 101 0zm4.9 23h44.3c45.8.0 58.3 3.5 70.3 17.5 11.8 13.2 12 30.1 12.5 62.9V156c.2 20.8.3 45.8-12.5 59.5-12 14-24.5 17.5-70.3 17.5h-44.3c-45.9.0-57.3-3.5-70.4-17.5-12.2-13-12.3-36.5-12.4-56.7v-55.6c.4-32.6.7-49.6 12.4-62.7C48 26.5 60 23 105.9 23zm19.6 144.5a42 42 0 100-84 42 42 0 000 84zm0 22.5a64.5 64.5.0 100-129 64.5 64.5.0 000 129z"/></svg>
<span>Instagram</span></a></div></div></div></aside></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2025 文字轨迹.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=../../../js/menu.js></script><script src=../../../js/custom.js></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML" async></script></body></html>