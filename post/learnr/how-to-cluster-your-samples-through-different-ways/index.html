<!doctype html><html class=no-js lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>如何聚类并挑选类 - 生信文集</title><script>(function(e,t){e[t]=e[t].replace("no-js","js")})(document.documentElement,"className")</script><meta name=description content><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=dns-prefetch href=//fonts.googleapis.com><link rel=dns-prefetch href=//fonts.gstatic.com><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Open+Sans:400,400i,700"><link rel=stylesheet href=../../../css/style.css><link rel="shortcut icon" href=../../../favicon.ico><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-204903359-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"))</script><script async src=https://www.google-analytics.com/analytics.js></script></head><body class=body><div class="container container--outer"><header class=header><div class="container header__container"><div class=logo><a class=logo__link href=../../../ title=生信文集 rel=home><div class="logo__item logo__text"><div class=logo__title>生信文集</div></div></a></div><nav class=menu><button class=menu__btn aria-haspopup=true aria-expanded=false tabindex=0>
<span class=menu__btn-title tabindex=-1>Menu</span></button><ul class=menu__list><li class=menu__item><a class=menu__link href=../../../blog/><span class=menu__text>文章</span></a></li><li class=menu__item><a class=menu__link href=../../../tags/><span class=menu__text>标签</span></a></li><li class=menu__item><a class=menu__link href=../../../about/><span class=menu__text>关于</span></a></li></ul></nav></div></header><div class="wrapper flex"><div class=primary><main class=main role=main><article class=post><header class=post__header><h1 class=post__title>如何聚类并挑选类</h1></header><div class="content post__content clearfix"><p>用来展示聚类三张图吧
<a href=https://mp.weixin.qq.com/s/_4lswhtg04_ctuIJYDhlJg><strong>这篇文章</strong></a> 提到了聚类展示的三张图，这里定义展示一下，也是对聚类概念的加强和理解；
<a href=https://mp.weixin.qq.com/s/AvUHjcU7XoMMUFM0KlU3bw><strong>原文地址</strong></a>
如何找到合适的聚类？</p><blockquote><p>不过我们可以基于不同聚类过程中使用的相似性算法和模块划分参数，选择一个最合适的数目。在K-means，PAM和层次聚类中选择合适的聚类数目，这些方法包括直接方法和统计检验方法。
1.<em>直接方法</em> 设置一些适合的划分标准，比如elbow和average silhouette法
2.<em>统计检验方法</em> 就是常用的假设检验方法，比如gap statistic</p></blockquote><pre tabindex=0><code class=language-{r}# data-lang={r}#># 如果因为缺少某些包而安装失败，请先安装其他依赖包再重新安装，安装时间比较久
# 可能需要依赖lme4，cowplot，ggpubr，FactoMineR
# 其中cowplot需要R3.3版本，其他版本可以试试用下面命令安装
devtools::install_url(&#34;https://github.com/wilkelab/cowplot/archive/1.0.0.zip&#34;)
if(!require(devtools)) install.packages(&#39;devtools&#39;)
if(!require(factoextra)) devtools::install_github(&#39;kassambara/factoextra&#39;)
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#>#如果已经安装，跳过即可
pkgs &lt;- c(&#34;cluster&#34;,  &#34;NbClust&#34;)
install.packages(pkgs)
</code></pre><p>载入R包</p><pre tabindex=0><code class=language-{r}# data-lang={r}#>library(factoextra)
library(cluster)
library(NbClust)
</code></pre><p>准备数据</p><pre tabindex=0><code class=language-{r}# data-lang={r}#>data(iris)
head(iris)
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#># remove species column
iris.scaled = scale(iris[,-5]) #scale 注意行 列，scale是对列进行操作
head(iris.scaled)
</code></pre><h2 id=1-三种聚类方法>1. 三种聚类方法</h2><h3 id=11-k-means-和-pama>1.1 k-means() 和 pama()</h3><p>这里演示了stat包中的k-means()，cluster包中的pama()的使用，把上面的归一化后的数据分成3个cluster。</p><pre tabindex=0><code class=language-{r}# data-lang={r}#># K-means clustering
set.seed(123)
km.res = kmeans(iris.scaled, 3, nstart=25)
# k-means  group number of each observation
str(km.res)
km.res$cluster
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#># visualize k-means result
fviz_cluster(km.res, data=iris.scaled, geom=&#39;point&#39;, stand=FALSE, ellipse.type=&#39;convex&#39;)
# convex / norm
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#># PAM clustering
pam.res = pam(iris.scaled, 3)
# str(pam.res)
pam.res$cluster
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#># visualize pam clusters
fviz_cluster(pam.res, stand=FALSE, geom=&#39;point&#39;, ellipse.type = &#39;norm&#39;)
</code></pre><h3 id=12-hclust>1.2 hclust()</h3><p>另一个是R中内建的方法hclust():</p><pre tabindex=0><code class=language-{r}# data-lang={r}#># 计算两两间的距离，计算方法比较多，这里选择欧几里德距离
dist.res = dist(iris.scaled, method=&#39;euclidean&#39;)
# 进行层次聚类，不同的算法说明可以查看函数帮助信息
hc = hclust(dist.res, method=&#39;complete&#39;)
# 展示聚类结果
plot(hc, labels=FALSE, hang=-1, xlab=&#39;hclust&#39;)
# 为3个group添加方框，原来还有这个函数，真神奇
rect.hclust(hc, k=3, border=2:4)
</code></pre><pre tabindex=0><code class=language-{r}# data-lang={r}#># 把层次聚类的结果分成3组 
hc.cut = cutree(hc,k=3)
hc.cut
</code></pre><h2 id=2-确定最佳分组数目的3种方法>2. 确定最佳分组数目的3种方法</h2><p>这里介绍3种常用的方法：<strong>Elbow method（肘部法则）</strong>，<strong>silhouette method</strong> 和 <strong>gap statistic</strong> 。</p><h3 id=21-elbow-method>2.1 Elbow method</h3><p>在聚类分割算法中，比如K-means聚类，为了确定不同的分类，需要保证每个类分组总变异量之和最小；
具体过程如下</p><blockquote></blockquote><p>1.对不同的k值，分别进行聚类。如K-means中k可以取从1到10
2.对每个k值，计算每个组的组内平方各（within-cluster sum of square）的和
3.绘制k值和组内平方和的总和的趋势图
4.从图上的转折点确定最佳分组数目</p><pre tabindex=0><code class=language-{r}# data-lang={r}#>#用kmeans看看
set.seed(123)  
# k值从2到15
k.max = 15
data = iris.scaled
# 这里不必手动计算平方总和，kmeans中已经完成计算，直接调用
wss = sapply(1:k.max,
            function(k){kmeans(data,k,nstart=10)$tot.withinss})
plot(1:k.max, wss,
    type=&#39;b&#39;, pch=19, frame=FALSE,
    xlab = &#39;Number of cluster K&#39;,
    ylab = &#34;Total within-clusters sum of squares&#34;)
abline(v=3, lty=2)
</code></pre><p>从上面的图，可以看出在k=3这个点上，曲线的变化率比较大，建议选择k=3作为最终的结果。当然你还可以看到k越大，组内平方和总和是越来越小，不过随着k变大，分类结果也更加分散，可能不能很好的表现数据聚类想要表达的信息。</p><p>也可以直接利用一个叫factoextra的R包来实现，使用它的提供的fviz_nbclust()函数</p><pre tabindex=0><code class=language-{r}# data-lang={r}#># fviz_nbclust(x,FUNcluster,method=c(&#39;silhourtte&#39;,&#39;wss&#39;))
fviz_nbclust(iris.scaled, kmeans, method=&#39;wss&#39;) + geom_vline(xintercept = 3, linetype=2)

# 这里貌似不能直接给出一个推荐值，需要我们自己从图中寻找一个，也就是k=3
</code></pre><p>下面试试用PAM聚类的结果进行测试</p><pre tabindex=0><code class=language-{r}# data-lang={r}#>fviz_nbclust(iris.scaled, pam, method=&#39;wss&#39;) + geom_vline(xintercept = 3, linetype=2)
</code></pre><p>最终结果也和k-means的聚类结果类似。最后再试试用层次聚类的结果来试试看。使用factoextra提供的 hcut对数据进行聚类并划分分组</p><pre tabindex=0><code class=language-{r}# data-lang={r}#>fviz_nbclust(iris.scaled, hcut, method=&#39;wss&#39;) + geom_vline(xintercept = 3, linetype=2)
</code></pre><p>如果数据比较复杂的话，Elbow method可能会陷入局部最优的结果，随着k的增大，wss反而又增大的情况。</p><h3 id=22-average-silhouette-method>2.2 Average silhouette method</h3><p>简单来说，该主方法用于评估聚类结果的质量。如果一个聚类的结果比较好，那么它的average silhouette就会比较高。计算过程类似Elbow method：</p><blockquote></blockquote><p>1.对不同的k值分别进行聚类
1.对每个k的聚类结果分别计算average silhouette（avg.sil）值
1.以k为x轴，avg.sil为y轴绘制连线图
1.avg.sil值最大处就是最优k值</p><p>具体的R执行代码可以利用cluster包中的silhouette()函数计算average silhouette值。先看看在K-means聚类中的使用</p><pre tabindex=0><code class=language-{r} data-lang={r}>library(cluster)
k.max = 15
data = iris.scaled
sil = rep(0, k.max)
# k从2到15分别进行kmeans 
for (i in 2:k.max){
    km.res = kmeans(data, centers=i, nstart = 25)
    ss = silhouette(km.res$cluster, dist(data))
    sil[i] = mean(ss[,3])
}
# 画图
plot(1:k.max, sil, type=&#39;b&#39;, pch=19, frame=FALSE, xlab=&#39;Number of clusters k&#39;)
abline(v=which.max(sil), lty=2)
</code></pre><p>使用前面用到的fviz_nbclust()完成</p><pre tabindex=0><code class=language-{r} data-lang={r}>fviz_nbclust(iris.scaled, kmeans, method=&#39;silhouette&#39;) #所以说这函数 标准化的数据、聚类方法和聚类评价方式
</code></pre><p>下面再介绍在PAM和层次聚类中使用</p><pre tabindex=0><code class=language-{r} data-lang={r}># for PAM clustering  
fviz_nbclust(iris.scaled, pam, method=&#39;silhouette&#39;)
</code></pre><pre tabindex=0><code class=language-{r} data-lang={r}># for hierarchical clustering
fviz_nbclust(iris.scaled, hcut, method=&#39;silhouette&#39;,hc_method=&#39;complete&#39;)
</code></pre><p>讨论:前面介绍的Elbow method得到的最佳值，需要我们手动去看，而Average silhouette method会直接提供一个最佳以供选择。而且K-means和PAM的推荐值是k=2，而层次聚类的推荐值是k=3。结合之前的Elbow method结果，设置k=3比较好。</p><h3 id=23-gap-statistic-method>2.3 Gap statistic method</h3><p>Gap statistic method可以运用到任何聚类算法里面。该方法先比较不同k值聚类结果中组内变异量的总和（total within intracluster variation）。
利用统计学的假设检验来比较TSS值与那些随机分布的参考数据集之间是否显著差异。</p><p>计算过程：（看不懂）</p><blockquote><p>根据不同的k值对实际数据进行聚类并计算$W_k$
产生B个参考数据集（bootstrap法），按照不同的k值进行聚类，并计算Gap值：$Gap(k) = \frac{1}{B}\sum{b=1}^{B}log(Wk^*) - log(W_k)$
让$\bar{w} = (\frac{1}{B}\sum{b}log(W{kb}^))$，计算标准差$sd(k) = \sqrt{\frac{1}{B}\sum_b(log(W_{kb}^)-\bar{w})^2}$和标准误$sk = sdk \times \sqrt{1+\frac{1}{B}}$
选择满足$Gap(k) \ge Gap(k+1) - s_{k+1}$的最小k值</p></blockquote><p>R语言里面的实现方法可以利用cluster包中的 clusGap()来计算</p><pre tabindex=0><code class=language-{r} data-lang={r}># clusGap(x, FUNcluster, K.max, B = 100, verbose = TRUE, ...)  
</code></pre><p>对3种聚类方法进行测试：</p><pre tabindex=0><code class=language-{r} data-lang={r}>library(cluster)
set.seed(123)
# 一般认为B=500就能得到一个比较好的结果，这里设为50以提高计算速度
gap_stat = clusGap(iris.scaled, FUN=kmeans, nstart=25, K.max=10, B=50)
print(gap_stat, method=&#39;firstmax&#39;)
</code></pre><pre tabindex=0><code class=language-{r} data-lang={r}># 绘图
plot(gap_stat, frame=FALSE, xlab=&#39;Number of cluster k&#39;)
abline(v=3, lty=2)
</code></pre><pre tabindex=0><code class=language-{r} data-lang={r}># 使用factoextra
fviz_gap_stat(gap_stat)
</code></pre><p>这里的最佳聚类数目是用firstmax方法（查看 ?cluster::maxSE）计算的，Tibshirani et al (2001)提出的方法可以参考下面脚本：</p><pre tabindex=0><code class=language-{r} data-lang={r}># Print
print(gap_stat, method = &#34;Tibs2001SEmax&#34;)
# Plot
fviz_gap_stat(gap_stat, 
            maxSE = list(method = &#34;Tibs2001SEmax&#34;))
# Relaxed the gap test to be within two standard deviations
fviz_gap_stat(gap_stat, 
          maxSE = list(method = &#34;Tibs2001SEmax&#34;, SE.factor = 2))
</code></pre><p>PAM和层次聚类的结果</p><pre tabindex=0><code class=language-{r} data-lang={r}># PAM聚类结果 
set.seed(123)
gap_stat &lt;- clusGap(iris.scaled, FUN = pam, K.max = 10, B = 50)
# Plot gap statistic
fviz_gap_stat(gap_stat)
</code></pre><pre tabindex=0><code class=language-{r} data-lang={r}># Compute gap statistic
set.seed(123)
gap_stat &lt;- clusGap(iris.scaled, FUN = hcut, K.max = 10, B = 50)
# Plot gap statistic
fviz_gap_stat(gap_stat)
</code></pre><p>原文参考：</p><ol><li><a href=https://mp.weixin.qq.com/s/AvUHjcU7XoMMUFM0KlU3bw>Determining the optimal number of clusters: 3 must known methods - Unsupervised Machine Learning</a></li><li><a href=https://rstudio-pubs-static.s3.amazonaws.com/201598_e96ae3be88b64ba8baffb2923bfdf5c6.html>k-means Clustering</a></li><li><a href=https://rpubs.com/Felix/7445>K-means another case</a></li><li><a href=https://mp.weixin.qq.com/s/AvUHjcU7XoMMUFM0KlU3bw>如何选聚类</a></li></ol></div><footer class=post__footer><div class="post__tags tags clearfix"><svg class="tags__badge icon icon-tag" width="16" height="16" viewBox="0 0 32 32"><path d="M32 19c0 1-1 2-1 2L21 31s-1 1-2 1-2-1-2-1L2 16c-1-1-1.4-2-1.4-2S0 12.5.0 11V3C0 1.5.8.8.8.8S1.5.0 3 0h8c1.5.0 3 .6 3 .6S15 1 16 2l15 15s1 1 1 2zM7 10a3 3 0 100-6 3 3 0 000 6z"/></svg><ul class=tags__list><li class=tags__item><a class="tags__link btn" href=../../../tags/r/ rel=tag>R</a></li><li class=tags__item><a class="tags__link btn" href=../../../tags/%E8%81%9A%E7%B1%BB/ rel=tag>聚类</a></li></ul></div></footer></article></main><section class=comments><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//kkitown.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></section></div></div><footer class=footer><div class="container footer__container flex"><div class=footer__copyright>&copy; 2022 生信文集.
<span class=footer__copyright-credits>Generated with <a href=https://gohugo.io/ rel="nofollow noopener" target=_blank>Hugo</a> and <a href=https://github.com/Vimux/Mainroad/ rel="nofollow noopener" target=_blank>Mainroad</a> theme.</span></div></div></footer></div><script async defer src=../../../js/menu.js></script></body></html>